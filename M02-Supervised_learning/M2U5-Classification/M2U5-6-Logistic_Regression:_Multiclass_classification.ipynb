{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d9c6ef-79eb-4635-9509-2936e0720f69",
   "metadata": {},
   "source": [
    "# Logistic Regression: Multiclass classification\n",
    "M2U5 - Exercise 6\n",
    "\n",
    "## What are we going to do?\n",
    "- We will create a synthetic dataset for multiclass logistic regression\n",
    "- We will preprocess the data\n",
    "- We will train the model on the training subset and check its suitability\n",
    "- We will find the optimal lambda regularization parameter using CV\n",
    "- We will make predictions about new examples\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md).\n",
    "\n",
    "## Instructions\n",
    "Having implemented the full training of a regularised logistic regression model for binary (2 classes) classification, we will repeat the same example for multiclass classification (3+ classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b59c0-28c9-4d2d-a8a5-ae0009f3ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f11be-ac10-4360-b017-a42fcf07398c",
   "metadata": {},
   "source": [
    "## Create a synthetic dataset for multiclass logistic regression\n",
    "\n",
    "We will create a synthetic 3-class dataset for this complete implementation.\n",
    "\n",
    "To do this, manually create a synthetic dataset for logistic regression with bias and error term (to have *Theta_true* available) with a slightly different code template than the one you used in the last exercise.\n",
    "\n",
    "For the multiclass classification we will calculate Y in a different way: And it will have 2D (m x classes) dimensions, to represent all possible classes. We call this encoding of e.g. [0, 0, 1] for the 3/3 class \"one-hot encoding\":\n",
    "\n",
    "- For each example and class, calculate *Y* with the sigmoid with *Theta_true* and *X*.\n",
    "- Transform the values of *Y* to be `0` o `1` according to the max. value of the sigmoid of all the classes.\n",
    "- Finally, transform the value of the class to 1 with a maximum value of the sigmoid, and the values of the other classes to 0, with a final ndarray for each example.\n",
    "\n",
    "To introduce an error term, it runs through all *Y* values and changes the class of that example to a random class with a random error rate.\n",
    "\n",
    "*NOTE:* Investigate how a synthetic dataset for multiclass classification could be achieved using Scikit-learn methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a9e47-7d6e-42be-afff-022e87606153",
   "metadata": {},
   "source": [
    "### Implement the sigmoid activation function\n",
    "\n",
    "Copy your function from previous exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f07fc-a338-48f7-970d-c68f0fd86cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0394f2b-0bbe-411c-99b9-a6dbf31b266b",
   "metadata": {},
   "source": [
    "Create the synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3ee5d-0f0a-43d5-8055-94dbfa9fce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Manually generate a synthetic dataset with a bias term and an error term\n",
    "# Since we are going to train so many models, generate a \"small\" dataset in order to train them quickly\n",
    "# If you need to, you can make it even smaller, or if you want more accuracy and a more realistic challenge, make it bigger\n",
    "m = 1000\n",
    "n = 2\n",
    "classes = 3\n",
    "\n",
    "# Generate a 2D m x n array with random values between -1 and 1\n",
    "# Insert a bias term as a first column of 1s\n",
    "X = [...]\n",
    "\n",
    "# Generate a 2D theta array with (classes x n + 1) random values\n",
    "Theta_true = [...]\n",
    "\n",
    "# Y shall have 2D dimensions of (m x classes)\n",
    "# Calculate Y with the sigmoid and transform its values to 0 or 1 and then to one-hot encoding\n",
    "for i in range(m):\n",
    "    for c in range(classes):\n",
    "        sigmoid_example = sigmoid([...])\n",
    "        # Assign the only class corresponding to the example according to the max. value of the sigmoid\n",
    "        Y[...] = [...]\n",
    "\n",
    "# To introduce an error term, go through all the Y values and change\n",
    "# the class chosen from that example to another random class with a random % error\n",
    "# Note: make sure that the other random class representing the error is different from the original one\n",
    "error = 0.15\n",
    "\n",
    "for j in range(m):\n",
    "    # If a random number is less than or equal to the error\n",
    "    if [...]:\n",
    "        # Assign a randomly selected class\n",
    "        Y[...] = [...]\n",
    "\n",
    "# Check the values and dimensions of the vectors\n",
    "print('Theta to be estimated:')\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d203bc-1c5c-4993-93fe-750697a7b9cd",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "As we did for linear regression, we will preprocess the data completely, following the usual 3 steps:\n",
    "\n",
    "- Randomly reorder the data..\n",
    "- Normalise the data..\n",
    "- Divide the dataset into training, validation, and test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c92dd-161b-4e9e-8f07-fc508137220e",
   "metadata": {},
   "source": [
    "### Randomly reorder the dataset\n",
    "\n",
    "Reorder the data in the *X* and *Y* dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fccf14-2ca5-41f7-afb0-ccd737d1ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468764a7-e182-4026-aa89-4ae068b5c4ec",
   "metadata": {},
   "source": [
    "### Normalizar el dataset\n",
    "\n",
    "Implementa la función de normalización y normaliza el dataset de ejemplos *X*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cecec13-4a02-48ef-8907-59a8b8c0ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "# Copia tu función de normalización utilizada en la unidad de regresión lineal\n",
    "def normalize(x, mu, std):\n",
    "    pass\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657316f-9a8a-40cc-9551-fb6945acc02c",
   "metadata": {},
   "source": [
    "*Nota*: Si habías modificado tu función *normalize* para que calculara y devolviera los valores de *mu* y *std*, puedes modificar esta celda para incluir tu código personalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdd699-3d04-4018-b485-de77e3f7d277",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento, validación y test\n",
    "\n",
    "Divide el dataset de *X* e *Y* en 3 subsets con el ratio habitual, 60%/20%/20%.\n",
    "\n",
    "Si tu nº de ejemplos es mucho más alto o bajo, siempre puedes modificar este ratio por otro como 50/25/25 o 80/10/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5743ce5-b995-4c15-8879-0f044a3e77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 3 subsets según los ratios indicados\n",
    "\n",
    "ratio = [60, 20, 20]\n",
    "print('Ratio:\\n', ratio, ratio[0] + ratio[1] + ratio[2])\n",
    "\n",
    "r = [0, 0]\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_val, X_test = [...]\n",
    "Y_train, Y_val, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12561eea-36a8-4089-a48e-3a4581772b73",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial para cada clase\n",
    "\n",
    "Para la clasificación multiclase, debemos entrenar un modelo diferente para cada clase. Por tanto, si tenemos 3 clases debemos entrenar 3 modelos diferentes.\n",
    "\n",
    "Cada modelo sólo considerará los valores de la variable objetivo relativos a su clase de una forma binaria, clasificando los ejemplos como pertenecientes a su clase o no.\n",
    "\n",
    "Para ello, sólo le proporcionaremos los valores de *Y* para dicha clase o columna. P. ej., para `Y = [[1, 0, 1], [0, 1, 0], [0, 0, 1]]`:\n",
    "- *Y* para el modelo 1: `[1, 0, 0]`\n",
    "- *Y* para el modelo 2: `[0, 1, 0]`\n",
    "- *Y* para el modelo 3: `[0, 0, 1]`\n",
    "\n",
    "Al igual que hacíamos en ejercicios anteriores, vamos a entrenar modelos iniciales para comprobar que nuestra implementación es correcta:\n",
    "- Entrena un modelo inicial sin regularización para cada clase.\n",
    "- Representa el histórico de la función de coste para comprobar su evolución para cada modelo.\n",
    "- Si es necesario, modifica cualquier hiper-parámetro, como el ratio de entrenamiento, y reentrena los modelos. Usarás dichos hiper-parámetros en siguientes puntos.\n",
    "\n",
    "Copia las celdas de ejercicios anteriores donde implementabas la función de coste y gradient descent regularizados para regresión logística y la celda donde entrenabas el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545782d-7cc8-467e-8adf-18941068fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia las celdas con las funciones de coste y gradient descent para clasificación regularizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650cd71-3b18-4490-802e-22a8dc645261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena tus modelos sobre el subset de entrenamiento sin regularizar\n",
    "\n",
    "# Crea una theta inicial con un valor dado, que puede ser el mismo para todos los modelos o no\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "iter_ = 1e3\n",
    "\n",
    "print('Hiper-arámetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "# Inicializa unas variables para almacenar el resultado de cada modelo con las dimensiones adecuadas\n",
    "# Cuidado: los modelos pueden necesitar un nº de iteraciones hasta que convergen diferente\n",
    "# Dale a j_train un tamaño para almacenar hasta el nº máx. de iteraciones, aunque no se rellenen todos los elementos\n",
    "j_train_ini = [...]\n",
    "theta_train = [...]\n",
    "\n",
    "t = time.time()\n",
    "for c in [...]:    # Itera sobre el nº de clases\n",
    "    print('\\nModelo para la clase nº:', c)\n",
    "    \n",
    "    theta_train = [...]    # Copia profunda de theta_ini para que no se modifique\n",
    "    \n",
    "    t_model = time.time()\n",
    "    j_train_ini[...], theta_train[...] = regularized_logistic_gradient_descent([...])\n",
    "    \n",
    "    print('Tiempo de entrenamiento para el modelo (s):', time.time() - t_model)\n",
    "    \n",
    "print('Tiempo de entrenamiento total (s):', time.time() - t)\n",
    "\n",
    "print('\\nCoste final del modelo para cada clase:')\n",
    "print()\n",
    "\n",
    "print('\\nTheta final del modelo para cada clase:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a976f61e-0957-4b58-942c-e48a6d65cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones para cada modelo\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title('Función de coste en cada clase')\n",
    "\n",
    "for c in range(clases):\n",
    "    plt.subplot(clases, 1, c + 1)\n",
    "    plt.xlabel('Iteraciones')\n",
    "    plt.ylabel('Coste clase {}'.format(c))\n",
    "    plt.plot(j_train_ini[...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee15b79-9f67-4c69-8aed-451f5f69551b",
   "metadata": {},
   "source": [
    "### Comprobar la idoneidad de los modelos\n",
    "\n",
    "Revisa la precisión de tus modelos y modifica los parámetros para reentrenarlos si es necesario.\n",
    "\n",
    "Recuerda que si tu dataset es \"demasiado preciso\" puedes volver a la celda original e introducir un término de error superior.\n",
    "\n",
    "Por complejidad de una clasificación multiclase, no te pediremos en esta ocasión que compruebes si los modelos pueden estar sufriendo desviación o sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd6a11-0929-48e5-8d35-240a019d0923",
   "metadata": {},
   "source": [
    "## Hallar el hiper-parámetro *lambda* óptimo por validación\n",
    "\n",
    "Del mismo modo que hemos hecho en ejercicios anteriores, vamos a optimizar nuestro parámetro de regularización por validación para cada una de las clases y modelos.\n",
    "\n",
    "Para ello, para cada clase, vamos a entrenar un modelo diferente por cada valor de *lambda* a considerar sobre el subset de entrenamiento, y evaluar su error o coste final sobre el subset de validación.\n",
    "\n",
    "De nuevo, vamos a representar gráficamente el error de cada modelo vs el valor de *lambda* usado e implementar un código que elija automáticamente el modelo más óptimo de entre todos para cada clase.\n",
    "\n",
    "Recuerda entrenar todos tus modelos en igualdad de condiciones, con los mismos hiper-parámetros.\n",
    "\n",
    "Por tanto, ahora debes modificar el código de la celda anterior para no entrenar un modelo como antes sino uno por clase y por cada uno de los valores de *lambda* a considerar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8fab78-1942-43b8-aa3c-2f202bd5d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente sobre X_train y evalúalo sobre X_val\n",
    "\n",
    "# Usa de nuevo un espacio logarítmico entre 10 y 10^3 de 5 elementos con valores que comiencen por un decimal no-cero 1 o 3\n",
    "# Al entrenar más modelos, podemos evaluar menos valores de lambda para reducir el tiempo de entrenamiento\n",
    "lambdas = [...]\n",
    "\n",
    "# Completa el código para entrenar un modelo diferente para cada clase y valor de lambda sobre X_train\n",
    "# Almacena sus thetas y costes finales\n",
    "# Posteriormente, evalúa sus costes totales en el subset de validación\n",
    "\n",
    "# Almacena dicha información en los siguientes arrays\n",
    "# Cuidado con sus dimensiones necesarias\n",
    "j_train = [...]\n",
    "j_val = [...]\n",
    "theta_val = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db658f-cf0b-4271-b93f-3c3835dce70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda con una gráfica por clase\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Completa con tu código\n",
    "for c in range(clases):\n",
    "    plt.subplot(clases, 1, c + 1)\n",
    "    \n",
    "    plt.title('Clase:', c)\n",
    "    plt.xlabel('Lambda')\n",
    "    plt.ylabel('Coste final')\n",
    "    plt.plot(j_train[...])\n",
    "    plt.plot(j_val[...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6b5b5-5288-472f-83f5-fe0b5191a358",
   "metadata": {},
   "source": [
    "### Escoger el mejor modelo para cada clase\n",
    "\n",
    "Copia el código de ejercicios anteriores y modifícalo para escoger el modelo con mayor precisión sobre el subset de validación para cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288db2e0-2697-4569-ab34-68baf0606efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge los modelos y valores de lambda óptimos, con el menor error sobre el subset de validación\n",
    "\n",
    "# Itera sobre todas las combinaciones de theta y lambda y escoge los modelos de menor coste en el subset de validación para cada clase\n",
    "\n",
    "j_final = [...]\n",
    "theta_final = [...]\n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71f987-c768-4668-928b-d83783d238a7",
   "metadata": {},
   "source": [
    "## Evaluar los modelos sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo de cada clase sobre un subset de datos que no hemos usado para entrenarlos ni para escoger ningún hiper-parámetro.\n",
    "\n",
    "Para ello, vamos a calcular el coste o error total sobre el subset de test y comprobar gráficamente los residuos sobre el mismo.\n",
    "\n",
    "Recuerda usar sólo las columnas de la *Y* que \"vería\" cada modelo, puesto que clasifica los ejemplos en función de si pertenecen a su clase o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a255d-2ab8-4f10-8a5e-ff2928ee9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error de los modelos sobre el subset de test usando la función de coste\n",
    "# Utiliza la theta y lambda del modelo específico de la clase correspondiente a dicho ejemplo\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c9941-fe87-4f09-9ecd-4a3536f48cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones de los modelos sobre el subset de test, calcula los residuos y represéntalos\n",
    "\n",
    "# Recuerda usar la función sigmoide para transformar las predicciones y escoger la clase según el valor máx. del sigmoide\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095fd04-6f43-4a4b-9c63-9af9d9455114",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestros modelos ya entrenados, optimizados y evaluados, lo único que nos queda es utilizarlos realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo para cada una de las clases, para cada uno de los 3 modelos.\n",
    "- Escoger la clase final como la clase con mayor valor de *Y* tras el sigmoide, aunque varios modelos predijeran `Y >= 0.0; Y = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e3488-0e99-4479-9807-fd584a025eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Para comparar, antes de normalizar los datos, usa la Theta_verd para ver cuál sería la clase real asociada\n",
    "Y_verd = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas del subset de entrenamiento\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo para cada modelo usando el sigmoide\n",
    "Y_pred = [...]\n",
    "\n",
    "# Escoge la clase final como la de mayor valor tras el sigmoide y transfórmala a un vector one-hot encoding de 0 y 1\n",
    "Y_pred = [...]\n",
    "\n",
    "# Compara la clase real asociada a dicho nuevo ejemplo y la clase predicha\n",
    "print('Clase real del nuevo ejemplo y clase predicha:')\n",
    "print(Y_verd)\n",
    "print(Y_pred)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
