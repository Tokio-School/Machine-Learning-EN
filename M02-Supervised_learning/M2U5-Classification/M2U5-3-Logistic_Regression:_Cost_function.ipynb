{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c330f7f-dfc7-4981-af4b-62c975587cea",
   "metadata": {},
   "source": [
    "# Logistic Regression: Cost function\n",
    "M2U5 - Exercise 3\n",
    "\n",
    "## What are we going to do?\n",
    "- We will create a synthetic dataset for logistic regression manually, and with Scikit-learn\n",
    "- We will implement the sigmoid logistic activation function\n",
    "- We will implement the cost function for logistic regression\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748824d-2e53-4cd4-b4fb-f37d09a8a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d76f5-c10b-4153-b79d-b8efd5d0f3f0",
   "metadata": {},
   "source": [
    "## Creation a synthetic dataset for logistic regression\n",
    "\n",
    "We are going to create a synthetic dataset again, but this time for logistic regression.\n",
    "\n",
    "We are going to discover how to do it with 2 methods we have used previously: manually, and with Scikit-learn, using the [sklearn_datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf4701-384c-468a-b36e-4ae8f73c6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Manually generate a synthetic dataset with a bias term and an error term\n",
    "m = 100\n",
    "n = 2\n",
    "\n",
    "# Generate a 2D m x n array with random values between -1 and 1\n",
    "# Insert a first column of 1s as a bias term\n",
    "X = [...]\n",
    "\n",
    "# Generate a theta array with n + 1 random values between [0, 1)\n",
    "Theta_true = [...]\n",
    "\n",
    "# Calculate Y as a function of X and Theta_true\n",
    "# Transform Y to values of 1 and 0 (float) when Y ≥ 0.0\n",
    "# Using a probability as the error term, iterate over Y and change the assigned class to its opposite, 1 to 0, and 0 to 1\n",
    "error = 0.15\n",
    "\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "\n",
    "# Check the values and dimensions of the vectors\n",
    "print('Theta and its dimensions to be estimated:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4f6d4-a5ae-421a-a782-f55718e726dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate a synthetic dataset with a bias term and an error term with Scikit-learn\n",
    "\n",
    "# Use the same values for m, n, and the error from the previous dataset\n",
    "X_sklearn = [...]\n",
    "Y_sklearn = [...]\n",
    "\n",
    "# Check the values and dimensions of the vectors\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094f456-908c-4818-98c7-873eb5fe4cd9",
   "metadata": {},
   "source": [
    "Since we cannot retrieve the previous coefficients with the Scikit-learn method, we will use the manual method for the rest of the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58898b2a-a012-4c9b-9ba5-7532ab5417da",
   "metadata": {},
   "source": [
    "## Implement the sigmoid function\n",
    "\n",
    "We are going to implement the sigmoid activation function. We will use this function to implement our hypothesis, which transforms the model’s predictions to values of 0 and 1.\n",
    "\n",
    "The sigmoid function:\n",
    "\n",
    "$$ g(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "$$ Y = h_\\theta(x) = g(X \\times \\Theta) = \\frac{1}{1 + e^{-x \\times \\Theta^T}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90355b88-39d0-479c-a868-fd5329739617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the sigmoid activation function\n",
    "\n",
    "def sigmoid(x, theta):\n",
    "    \"\"\" Returns the value of the sigmoid for said x and theta\n",
    "    \n",
    "    Positional arguments:\n",
    "    x -- ndarray 1D with the features of an example\n",
    "    theta -- ndarray 1D with the row or column with the coefficients of the features\n",
    "    \n",
    "    Return:\n",
    "    sigmoid -- float (0., 1.) with the value of the sigmoid for these parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    sigmoid = [...]\n",
    "    \n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275242c7-e630-4e79-802b-27d0662301cd",
   "metadata": {},
   "source": [
    "Now plot the result of your function to check its implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78890bc-f2d5-4b0d-973b-40dbbaf0556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the result of the sigmoid function\n",
    "# For the horizontal axis, use a Z in the linear space [-10, 10] of 100 elements\n",
    "# Plot the values of g(z) as a line and dot plot\n",
    "# Compare the result of the sigmoid with Y, as a dot plot with different coloured dots\n",
    "# For the graph, include a title, legend, grid, and ticks on the relevant vertical axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f01a2-8c52-4940-a378-e7f6eb61f18c",
   "metadata": {},
   "source": [
    "## Implement the cost function\n",
    "\n",
    "We are going to implement the non-regularised cost function. This function will be similar to the one we implemented for linear regression in a previous exercise.\n",
    "\n",
    "Cost function:\n",
    "\n",
    "$$ Y = h_\\Theta(x) = g(X \\times \\Theta^T) $$\n",
    "$$ J(\\Theta) = - [\\frac{1}{m} \\sum\\limits_{i=0}^{m} (y^i log(h_\\theta(x^i)) + (1 - y^i) log(1 - h_\\theta(x^i))] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868189d0-c9d1-4cdd-8d68-7f1bbac3e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the non-regularised cost function for logistic regression\n",
    "\n",
    "def logistic_cost_function(x, y, theta):\n",
    "    \"\"\" Computes the cost function for the considered dataset and coefficients\n",
    "    \n",
    "    Positional arguments:\n",
    "    x -- ndarray 2D with the values of the independent variables from the examples, of size m x n\n",
    "    y -- ndarray 1D with the dependent/target variable, of size m x 1 and values of 0 or 1\n",
    "    theta -- ndarray 1D with the weights of the model coefficients, of size 1 x n (row vector)\n",
    "    \n",
    "    Return:\n",
    "    j -- float with the cost for this theta array\n",
    "    \"\"\"\n",
    "    m = [...]\n",
    "    \n",
    "    # Remember to check the dimensions of the matrix multiplication to perform it correctly\n",
    "    j = [...]\n",
    "    \n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c07878-475e-4312-ba1a-945a1096e8a7",
   "metadata": {},
   "source": [
    "As in previous exercises, test your implementation by calculating the cost function for each instance of the dataset.\n",
    "\n",
    "Check that it returns a float scalar, and not a ndarray. Use `np.reshape()` for your matrix multiplications, if necessary.\n",
    "\n",
    "With the correct *theta*, the cost function should be 0. As *theta* moves away from *Theta_true*, the cost should increase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14099fa4-5f7c-4a00-820e-0187619e7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your implementation on the dataset\n",
    "\n",
    "theta = Theta_true    # Modify and test several values of theta\n",
    "\n",
    "j = logistic_cost_function(X, Y, theta)\n",
    "\n",
    "print('Cost of the model:')\n",
    "print(j)\n",
    "print('Checked theta and Actual theta:')\n",
    "print(theta)\n",
    "print(Theta_true)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
