{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c3d42e-4278-4e97-80b1-29c7bd9dca9e",
   "metadata": {},
   "source": [
    "# Logistic Regression: Training and predictions\n",
    "M2U5 - Exercise 4\n",
    "\n",
    "## What are we going to do?\n",
    "- We will create a synthetic dataset for logistic regression\n",
    "- We will preprocess the data\n",
    "- We will train the model using gradient descent\n",
    "- We will check the training by plotting the evolution of the cost function\n",
    "- We will make predictions about new examples\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md).\n",
    "\n",
    "## Instructions\n",
    "Once the cost function is implemented, we will train a gradient descent logistic regression model, testing our training, evaluating it on a test subset and finally, making predictions on it.\n",
    "\n",
    "This time we will work with a binary logistic regression, while in other exercises we will consider a multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75001ae7-ec7a-404c-b18e-626111215ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c8385-e9ef-4891-a6e1-5a32415301d0",
   "metadata": {},
   "source": [
    "## Create a synthetic dataset for logistic regression\n",
    "\n",
    "We will create a synthetic dataset with only 2 classes (0 and 1) to test this implementation of a fully trained binary classification model, step by step.\n",
    "\n",
    "To do this, manually create a synthetic dataset for logistic regression with bias and error term (to have *Theta_true* available) with the code you used in the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e34da-36ff-4d10-82aa-a23368c62f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Manually generate a synthetic dataset with a bias term and an error term\n",
    "m = 100\n",
    "n = 1\n",
    "\n",
    "# Generate a 2D m x n array with random values between -1 and 1\n",
    "# Insert a bias term as a first column of 1s\n",
    "X = [...]\n",
    "\n",
    "# Generate a theta array with n + 1 random values between [0, 1)\n",
    "Theta_true = [...]\n",
    "\n",
    "# Calculate Y as a function of X and Theta_true\n",
    "# Transform Y to values of 1 and 0 (float) when Y ≥ 0.0\n",
    "# Using a probability as the error term, iterate over Y and change the assigned class to its opposite, 1 to 0, and 0 to 1\n",
    "error = 0.15\n",
    "\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "\n",
    "# Check the values and dimensions of the vectors\n",
    "print('Theta and its dimensions to be estimated:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104d14f-d030-4080-8857-f5b87b7ec9bf",
   "metadata": {},
   "source": [
    "## Implement the sigmoid activation function\n",
    "\n",
    "Copy your cell with the sigmoid function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c1160-8942-4119-93a1-c9fc9e51842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af47ac7-c02e-4e8c-8aa1-ec4ce7fa2109",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "As we did for linear regression, we will preprocess the data completely, following the usual 3 steps:\n",
    "\n",
    "- Randomly reorder the data.\n",
    "- Normalise the data.\n",
    "- Divide the dataset into training and test subsets.\n",
    "\n",
    "You can do this manually or with Scikit-learn's auxiliary functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f6925-be52-4e3f-afe5-145319c40611",
   "metadata": {},
   "source": [
    "### Reordenar el dataset aleatoriamente\n",
    "\n",
    "Reordena los datos del dataset *X* e *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a26f38-d730-456d-9154-7500c2d86b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659a404-06e7-4d25-b542-35c1a36332bb",
   "metadata": {},
   "source": [
    "### Normalizar el dataset\n",
    "\n",
    "Implementa la función de normalización y normaliza el dataset de ejemplos *X*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28586e-67db-4555-8e9f-606a17871561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "# Copia tu función de normalización utilizada en la unidad de regresión lineal\n",
    "def normalize(x, mu, std):\n",
    "    pass\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325eadb3-b554-48f1-8502-80f3bc962a5f",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento y test\n",
    "\n",
    "Divide el dataset de *X* e *Y* en 2 subsets con el ratio de 70%/30%.\n",
    "\n",
    "Si tu nº de ejemplos es mucho más alto o bajo, siempre puedes modificar este ratio más adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a5f7f-443b-43f9-8dd9-e18391a647d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 2 subsets según el ratio indicado\n",
    "\n",
    "ratio = [70, 30]\n",
    "print('Ratio:\\n', ratio, ratio[0] + ratio[1])\n",
    "\n",
    "# Índice de corte\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_test = [...]\n",
    "Y_train, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc8050-7a75-4e4d-b118-495a09e6d759",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial sobre el subset de entrenamiento\n",
    "\n",
    "Al igual que hacíamos en ejercicios anteriores, vamos a entrenar un modelo inicial para comprobar que nuestra implementación y el dataset trabajan correctamente, y posteriormente podremos entrenar un modelo con validación sin problema.\n",
    "\n",
    "Para ello, sigue los mismos pasos que seguiste para la regresión lineal:\n",
    "- Entrena un modelo inicial sin implementar la regularización.\n",
    "- Representa el histórico de la función de coste para comprobar su evolución.\n",
    "- Si es necesario, modifica cualquier parámetro y reentrena el modelo. Usarás dichos parámetros en siguientes puntos.\n",
    "\n",
    "Copia las celdas de ejercicios anteriores donde implementabas la función de coste en regresión logística, el gradient descent sin regularizar para regresión lineal y la celda donde entrenabas el modelo de regresión, y modifícalas para el caso de la regresión logística.\n",
    "\n",
    "Recuerda las funciones de descenso de gradiente para regresión logística:\n",
    "\n",
    "$$ Y = h_\\Theta(x) = g(X \\times \\Theta^T) $$\n",
    "$$ \\theta_j := \\theta_j - \\alpha [\\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_j^i] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630ea2f-e1c7-477f-865f-f09bb26f4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda con la función de coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f44be2-e863-4856-b08a-04f639092ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda con la función de descenso de gradiente sin regularizar para regresión lineal y adáptala para regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21bacf5-2af3-4900-b810-2ff9edd7f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda donde entrenamos el modelo\n",
    "# Entrena tu modelo sobre el subset de entrenamiento sin regularizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be70b0-10fe-482b-aa24-b2dcd4f38000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9108c89-0d80-4001-87d6-b21bd30c32b0",
   "metadata": {},
   "source": [
    "Comprueba tu implementación en estas circunstancias:\n",
    "1. Usando *Theta_verd*, el coste final debe ser prácticamente 0 y converger en un par de iteraciones.\n",
    "1. Según los valores de *theta* se alejen de *Theta_verd*, debe necesitar más iteraciones y la *theta_final* debe ser muy similar a la *Theta_verd*.\n",
    "\n",
    "Para ello recuerda que puedes modificar los valores de las celdas y reejecutarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1022f9-323e-4ff3-bcdd-030558f2f966",
   "metadata": {},
   "source": [
    "Anota tus experimentos y resultados en esta celda (en Markdown o código):\n",
    "1. Experimento 1\n",
    "1. Experimento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad87473-1622-4e42-adb3-507d60607562",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo sobre un subset de datos que no hemos usado para entrenarlo.\n",
    "\n",
    "Para ello, vamos a calcular el coste o error total sobre el subset de test y comprobar gráficamente los residuos sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10047f-8f27-4994-aac1-045b1a030f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error del modelo sobre el subset de test usando la función de coste con la correspondientes theta\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc3271-f2b7-4672-9e1b-570647bbee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones del modelo sobre el subset de test, calcula los residuos y represéntalos frente al índice de ejemplos (m)\n",
    "\n",
    "# Recuerda usar la función sigmoide para transformar las predicciones\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c322b-bbbe-4536-a62f-d460c20cdc43",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestro modelo ya entrenado y evaluado, lo único que nos queda es ponerlo en funcionamiento realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4170c69-9850-4069-89da-70d715e6b4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias y error aleatorio\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas originales\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "Y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
