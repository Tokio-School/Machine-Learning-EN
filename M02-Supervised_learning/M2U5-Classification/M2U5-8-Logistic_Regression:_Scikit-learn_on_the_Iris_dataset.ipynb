{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4855011-3b93-4a3e-bc31-eef0e0ebb5ce",
   "metadata": {},
   "source": [
    "# Logistic Regression: Scikit-learn on the Iris dataset\n",
    "M2U5 - Exercise 8\n",
    "\n",
    "## What are we going to do?\n",
    "- We will download the Iris dataset\n",
    "- We will preprocess the dataset using Scikit-learn methods\n",
    "- We will train a multiclass classification model using Scikit-learn\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md).\n",
    "\n",
    "## Instructions\n",
    "We will now solve the same model using Scikit-learn methods.\n",
    "\n",
    "You can use the following example as a reference for this exercise: [Logistic regression 3-class classifier](https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96019293-1fb4-4588-92d7-65ce9faf3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all the necessary modules into this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9a277-8410-432b-9283-abb326208c4f",
   "metadata": {},
   "source": [
    "## Load the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b20f51-eb3f-44bc-ae17-e3d778870944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the Iris dataset as X and Y arraysY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ea0c8-8c2e-43e7-a2eb-f8d7625f6e81",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "Preprocess the data using Scikit-learn methods, as you did in the Scikit-learn linear regression exercise:\n",
    "\n",
    "- Randomly reorder the data.\n",
    "- Normalise the data, if necessary.\n",
    "- Divide the dataset into training and test subsets.\n",
    "\n",
    "On this occasion, we will use K-fold cross-validation, as the dataset is very small (150 examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28c5f5-97c0-4b2d-8eb5-18c30d1eaaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Randomly reorder the data, normalise it only if necessary, and divide it into training and test subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92842c-70a6-4841-801e-6f153a68fb2e",
   "metadata": {},
   "source": [
    "## Train an initial model\n",
    "- Train an initial model on the training subset without regularisation.\n",
    "- Test the suitability of the model and retrain it if necessary.\n",
    "\n",
    "The Scikit-learn function that you can use is [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) with an OvR scheme (\"one-vs-rest\", one class versus the rest).\n",
    "\n",
    "Evaluate it on the test subset using its `model.score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc88c4-de10-4db3-ae16-df0daf2326f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model on the unregularised training subset and evaluate it on the test subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c71a85-f30d-435a-812c-66e91d700107",
   "metadata": {},
   "source": [
    "## Find the optimal regularisation using cross-validation\n",
    "- Train a model for each regularisation value to be considered.\n",
    "- Train and evaluate them on a training subset fold using K-fold.\n",
    "- Choose the optimal model and its regularisation.\n",
    "\n",
    "The LogisticRegression method applies an L2 regularisation by default, although it uses the *C* parameter which represents the inverse of *lambda*. Therefore, the lower the values, the greater the regularisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d895f0-9fc9-408b-85b6-ccde84b6d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a different model for each C on a different K-fold\n",
    "\n",
    "# Use the values of lambda that we considered in previous exercises\n",
    "lambdas = [0., 1e-1, 1e1, 1e2, 1e3]\n",
    "# Calculate C for each lambda\n",
    "cs = [...]\n",
    "\n",
    "# Create 5 K-fold splits\n",
    "kf = [...]\n",
    "\n",
    "# Iterate over the 5 splits for your models and evaluate them on the generated CV subset\n",
    "log_models = []\n",
    "best_model = None\n",
    "for train, cv in kf.split(X):\n",
    "    # Train a model on the training subset\n",
    "    # Remember to set the corresponding C parameter\n",
    "    # Evaluate it on the cv subset using its method score()\n",
    "    # Save the model with the best score for the best_model variable and display the C of the best model\n",
    "    c = [...]\n",
    "    print('L2 regularisation used:', c)\n",
    "    \n",
    "    log_models[...] = [...]\n",
    "    \n",
    "    # If the model is better than the best model so far...\n",
    "    best_model = [...]\n",
    "    print('L2 regularisation of the best model so far:', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616aade-4137-469a-9d8f-b034c0526adf",
   "metadata": {},
   "source": [
    "## Finally, evaluate the model on the test subset\n",
    "\n",
    "- Display the coefficients and intercept of the best model.\n",
    "- Evaluate the model on the test subset.\n",
    "- Calculate the hits and misses on the test subset as in the linked example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462cc168-03a0-4a10-afb4-1d7737f97802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the best model on the initial test subset\n",
    "\n",
    "# Display the coefficients and intercept of the best trained model\n",
    "print('Intercept coefficients of the trained model')\n",
    "print()    # Display the intercept as the first coefficient\n",
    "\n",
    "# Make predictions on the test subset\n",
    "y_test_pred = [...]\n",
    "\n",
    "# Calculate the average (\"accuracy\") model evaluation metrics (its method score())\n",
    "mean_accuracy = [...]\n",
    "\n",
    "print('Mean accuracy: %.2f' % mean_accuracy)\n",
    "\n",
    "# Calculate the hits and misses on the test subset and plot them graphically\n",
    "results = [...]\n",
    "\n",
    "# Plot them graphically\n",
    "plt.figure(1)\n",
    "\n",
    "# Fill in your code\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
