{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e3e64e-14a0-4779-83f8-c94bf9837a8e",
   "metadata": {},
   "source": [
    "# Decision Trees: Scikit-Learn\n",
    "M2U5 - Exercise 1\n",
    "\n",
    "## What are we going to do?\n",
    "- We will train a linear regression model using decision trees\n",
    "- We will check to see if there is any deviation or overfitting in the model\n",
    "- We will optimise the hyperparameters with validation\n",
    "- We will evaluate the model on the test subset\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md).\n",
    "\n",
    "## Instructions\n",
    "We are going to solve a multivariate linear regression problem similar to the previous exercises, but this time using a decision tree for linear regression.\n",
    "\n",
    "An example that you can use as a reference for this exercise: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95184942-7bea-4ee5-8d0c-656fb4c48320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all the necessary modules into this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1c0ae-9e95-43d4-8957-75d94c6d8f8f",
   "metadata": {},
   "source": [
    "## Generate a synthetic dataset\n",
    "\n",
    "Generate a synthetic dataset with a fairly large error term and few features, manually or with Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ad192-bcbe-4785-88a9-3b5d93f7fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate a synthetic dataset, with few features and a significant error term\n",
    "# Do not add a bias term to X\n",
    "\n",
    "m = 1000\n",
    "n = 2\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_true = [...]\n",
    "\n",
    "error = 0.3\n",
    "\n",
    "Y = [...]\n",
    "\n",
    "# Check the values and dimensions of the vectors\n",
    "print('Theta and its dimensions to be estimated:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74217537-2ce8-4899-a3a2-4a4167403df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Graphically represent the dataset in 3D to ensure that the error term is sufficiently high\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc5107-d438-4274-ae4b-276caacf5717",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "- Randomly reorder the data.\n",
    "- Nomalise the data..\n",
    "- Divídelos en subsets de entrenamiento y test.\n",
    "\n",
    "*Nota*: De nuevo usaremos K-fold para la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089aed7-ffe9-4fca-876b-1309f1c2bae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente, normaliza los ejemplos y dividelos en subsets de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bfae5-5e7d-4d73-8248-078475322835",
   "metadata": {},
   "source": [
    "## Entrena un modelo inicial\n",
    "\n",
    "Vamos a comenzar a explorar los modelos de árboles de decisión para regresión con un modelo inicial.\n",
    "\n",
    "Para ello, entrena un modelo de [sklearn.tree.DecissionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) sobre el subset de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143acbfd-4652-44b5-ba0f-6b4c776c35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un árbol de regresión sobre el subset de entrenamiento con una profundidad máx. de 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694b7ab-2c5f-4e86-b054-f92c1be46861",
   "metadata": {},
   "source": [
    "Ahora comprueba la idoneidad del modelo evaluándolo sobre el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b9a6f-ca82-41ff-b085-41b772ef4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 sobre el subset de test\n",
    "\n",
    "y_test_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a626f-e438-47c6-b378-9f94e7c592f1",
   "metadata": {},
   "source": [
    "*PREGUNTA:*\n",
    "*¿Crees que se da desviación o sobreajuste en dicho modelo?*\n",
    "\n",
    "Para ello, compara su precisión con la calculada sobre el subset de entrenamiento y responde en esta celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e6999-1e04-4944-b9bc-e21b94af45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 ahora sobre el subset de entrenamiento\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb79b07-efd4-4f9c-a8ce-68d1b1fb23d6",
   "metadata": {},
   "source": [
    "Como decíamos, los árboles de decisión tienden a sobreajustar, a ajustarse demasiado a los datos usados para entrenarlo y a veces no poder predecir bien sobre nuevos ejemplos.\n",
    "\n",
    "Vamos a comprobarlo gráficamente entrenando otro modelo con una profundidad máxima mucho mayor, de 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4b2b5-06d3-4aa3-91e6-b7f5be9ddf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena otro árbol de regresión sobre el subset de entrenamiento con profundidad máx. de 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6fdca-0857-4f92-9947-8bfdf36645b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 sobre el subset de entrenamiento\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17f0d8-cf13-4c8f-b728-aeedf14e2cc2",
   "metadata": {},
   "source": [
    "Compara la precisión del entrenamiento de este modelo con el anterior (sobre el subset de entrenamiento).\n",
    "\n",
    "*PREGUNTA:* ¿Es mayor o menor al aumentar la profundidad máxima del árbol?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d66ae-7c62-4855-bfe3-ea9bce8e1626",
   "metadata": {},
   "source": [
    "Ahora vamos a representar gráficamente ambos modelos, para comprobar si sufren desviación o sobreajuste.\n",
    "\n",
    "Para hacerlo, puedes guiarte por el ejemplo anterior: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e172c-0a55-4d2d-8897-788bdea1521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente las predicciones de ambos modelos\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representa en un gráfico de puntos el subset de entrenamiento para la característica 1 y 2 (con formas diferentes)\n",
    "plt.scatter([...])\n",
    "plt.scatter([...])\n",
    "# Representa en un gráfico de puntos el subset de test para la característica 1 y 2 (con formas diferentes), con un color diferente respecto al subset de entrenamiento\n",
    "plt.scatter([...])\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representa en un gráfico de líneas las predicciones de ambos modelos, con colores diferentes y una leyenda para distinguirlos\n",
    "# Como eje horizontal, usa un espacio lineal de un gran nº de elementos entre el valor máx. y mín. de ambas características de X\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94159082-275b-41f6-96fc-add6d750ef60",
   "metadata": {},
   "source": [
    "Como hemos podido comprobar, generalmente una profundidad máx. demasiado pequeña lleva a un modelo con desviación, un modelo que no es capaz de ajustar suficientemente bien la curva, mientras que una profundidad máx. demasiado alta lleva a un modelo con sobreajuste, un modelo que ajusta demasiado bien la curva, pero que no tiene una buena precisión en ejemplos futuros.\n",
    "\n",
    "Por tanto, entre todos los hiper-parámetros de los árboles de regresión, tenemos la profundidad máxima, que debemos optimizar por validación. También hay otros hiper-parámetros, como el criterio para medir la calidad de una división, la estrategia para crear esa división, el nº mín. de ejemplos necesario para dividir un nodo, etc.\n",
    "\n",
    "Por simpleza, vamos a comenzar realizando una validación cruzada sólo para hallar el valor óptimo de la profunidad máxima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232a8a6-5f03-4e35-a1ed-354c6b069bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo diferente para cada valor de max_depth considerado sobre un fold diferente\n",
    "\n",
    "# Valores de max_depth a considerar en un espacio de nºs enteros [1, 8]\n",
    "max_depths = [...]\n",
    "print('Profundidades máx. a considerar:')\n",
    "print(max_depths)\n",
    "\n",
    "# Crea x splits de K-fold, uno por cada valor de max_depth a considerar\n",
    "kf = [...]\n",
    "\n",
    "# Itera sobre los splits, entrena tus modelos y evalúalos sobre el subset de CV generado\n",
    "linear_models = []\n",
    "best_model = None\n",
    "for train, cv in kf.split(X):\n",
    "    # Entrena un modelo sobre el subset train\n",
    "    # Evalúalo sobre el subset cv usando su método score()\n",
    "    # Guarda el modelo con el mejor score en la variable best_model y muestra el alpha del mejor modelo\n",
    "    alpha = [...]\n",
    "    print('Profundidad máx. usada:', max_depth)\n",
    "    \n",
    "    linear_models.append([...])\n",
    "    \n",
    "    # Si el modelo es mejor que el mejor modelo hasta ahora, actualiza el mejor modelo encontrado\n",
    "    best_model = [...]\n",
    "    \n",
    "    print('Profundidad máx. y R^2 del mejor árbol hasta ahora:', max_depth, best_model.score([...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184ab37-bcf6-47e5-95a3-97af7ef39a4e",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo sobre el subset de test.\n",
    "\n",
    "Para ello, calcula sus métricas de MSE, RMSE y R^2 y representa gráficamente las predicciones del modelo y residuos vs el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3137f-e553-41b7-a4b1-bece2e99d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 sobre el subset de test\n",
    "\n",
    "y_train_test = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75456c34-bdf9-4d1c-8d92-986575db190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente las predicciones del mejor árbol sobre el subset de test y sus residuos\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representa en un gráfico de puntos el subset de test, mostrando ambas características con una forma diferente\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representa en un gráfico de líneas las predicciones del modelo\n",
    "# Como eje horizontal, usa un espacio lineal de un gran nº de elementos entre el valor máx. y mín. de las características de X_test\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "# Calcula los residuos y represéntalos como un gráfico de barras sobre el eje horizontal\n",
    "residuals = [...]\n",
    "\n",
    "plt.bar([...]\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
