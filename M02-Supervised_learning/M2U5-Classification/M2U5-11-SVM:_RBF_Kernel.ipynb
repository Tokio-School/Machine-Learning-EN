{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfddb7f-4dab-49f6-8c98-b96f539571e9",
   "metadata": {},
   "source": [
    "# SVM: RBF Kernel\n",
    "M2U5 - Exercise 11\n",
    "\n",
    "## What are we going to do?\n",
    "- We will generate a 2-class (binary) synthetic dataset\n",
    "- We will preprocess the dataset\n",
    "- We will train a classification model on the same dataset using SVM\n",
    "- We will check its suitability\n",
    "- Using validation, we will optimise the hyperparameters of our model\n",
    "- We will evaluate our model\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md).\n",
    "\n",
    "## Instructions\n",
    "Just as we had done for logistic regression classification using Scikit-learn, we are now going to use it to solve SVM classification problems.\n",
    "\n",
    "Specifically, we are going to use its SVC classifier with the RBF (\"Radial Basis Function\") kernel. The Scikit-learn SVC model has several kernels available, and the Gaussian kernel in particular is not among them. However, the RBF kernel is closely related to it since it also starts from a \"radial\" classification, and in real projects it can actually be more efficient and perform better than the Gaussian kernel.\n",
    "\n",
    "Therefore, instead of the Gaussian kernel we will use the RBF.\n",
    "\n",
    "This SVM kernel has 2 parameters:\n",
    "- *C*: The inverse of the regularisation parameter. For larger values of *C*, a smaller inter-class margin will be accepted if the decision function better classifies the training examples. Lower values of *C* will attempt to increase the margin between classes, using a simpler decision function, possibly resulting in a lower accuracy.\n",
    "- *Gamma*: Defines how far the influence of each example extends, or the inverse of the radius of influence of the examples selected by the model as \"landmarks\". Lower values will mean a more far-reaching influence and higher values a much closer influence.\n",
    "\n",
    "We will optimise both parameters using cross-validation.\n",
    "\n",
    "As a reference for this exercise, you can use these links from the documentation:\n",
    "- [SVM: Classification](https://scikit-learn.org/stable/modules/svm.html#classification)\n",
    "- [skelarn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)\n",
    "- [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html)\n",
    "- [Non-linear SVM](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21428169-00d2-467b-924a-42816c8a5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all the necessary modules into this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09111ef7-73f9-4e58-8d5b-cfd93fd5ec05",
   "metadata": {},
   "source": [
    "## Create a synthetic binary classification dataset\n",
    "\n",
    "Create a dataset for 2-class classification with [sklearn.datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html).\n",
    "\n",
    "Remember to use parameters that we can later modify, such as the number of examples, features, and classes, whether we want it to be unordered or not, a constant initial random state, number of clusters, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36d327-eac4-4393-8f4e-99295fc7c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a synthetic dataset for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a493b-8bd5-40a6-9924-caa503912a86",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "Preprocess the data::\n",
    "- Randomly reorder the data.\n",
    "- Normalise the data.\n",
    "- Divide into training and test subsets (we will use CV by K-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef9dfd-bdc2-4085-a165-fc96e55b1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Randomly reorder the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff81c69-4dd3-44b8-9c8f-9618e3c00155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalise the data if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209dcf36-69b7-44db-a617-6cd7fe7f5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide into training, CV, and test subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc8b49-e994-4c1b-883c-cacd605bbfe8",
   "metadata": {},
   "source": [
    "## Train an initial classification model using SVM\n",
    "\n",
    "To check the performance of our SVC classifier before optimising it by cross-validation, we will train an initial model on the training subset and validate it on the test subset.\n",
    "\n",
    "Remember, use the [decision_function_shape](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification)function to use the \"one versus the rest\" (OVR).\n",
    "\n",
    "Use the default values for *C* and *gamma* so as not to influence their regularisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786f1ed-4904-4c4d-8927-22fb80dd7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train an SVC model without modifying the regularisation parameters on the training subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb5add-dd9c-411e-8835-b4e4a4abd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the model with its model.score() on the test subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05334b7-cdc8-4d3f-b7ec-6349697e0e6b",
   "metadata": {},
   "source": [
    "A very graphical way to better understand how SVMs work and to check the accuracy of your model is to represent the hyperplane that now separates the classes, whose margin with the classes we are trying to maximise.\n",
    "\n",
    "To represent this, remember that you can follow the [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html) example and modifiy its code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6c85d-4e41-4ada-ad12-413a09c7d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the separation hyperplane with the class margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7e6c0-84c3-42a8-873a-257d45017aa9",
   "metadata": {},
   "source": [
    "## Optimise the regularization hyperparameters using cross-validation\n",
    "\n",
    "Once again we are going to use [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to optimise our *C* and *gamma* hyperparameters using K-fold at the same time this time, and visually represent their possible values.\n",
    "\n",
    "A very interesting example of this as we have mentioned is [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).\n",
    "\n",
    "Modify its code to optimise our model on our synthetic dataset, using K-fold to optimise *C* and *gamma*. You can use the same logarithmic range of values for these hyperparameters or adapt it to this dataset.\n",
    "\n",
    "*Note*: Remember that we have previously preprocessed the dataset following our usual methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3fa65-d3ce-4954-89b6-6d8eb91e165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optimize the SVC hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365236e2-550d-43d7-872c-1564c9a3fc97",
   "metadata": {},
   "source": [
    "*Note*: Sometimes it is a good idea to split the code into different cells in order to be able to modify and re-execute them independently, especially when it takes time to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f468afd-03ea-4b00-ae34-7a25eef7e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the effect of the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd419fa3-5e40-4322-8ead-416628db9e57",
   "metadata": {},
   "source": [
    "## Finally, evaluate the model on the test subset\n",
    "- Display the coefficients and intercept of the best model.\n",
    "- Evaluate the best model on the initial test subset.\n",
    "- Plot the class predictions to check hits, misses and the margin between classes on the new hyperplane.\n",
    "\n",
    "To represent the predictions and the hyperplane margin between classes, you can reuse the code you used to evaluate the initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0b921-f006-4ebf-99c0-1d3c1f3ca87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the best model on the initial test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f562b66-1084-4dec-a694-763cfe305064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the predictions, check the accuracy and the margin between classes"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
