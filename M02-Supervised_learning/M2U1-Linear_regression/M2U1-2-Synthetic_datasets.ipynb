{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ae2b82-6c66-4298-af76-72364ff94e03",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression: Synthetic datasets\n",
    "M2U1 - Exercise 2\n",
    "\n",
    "## What are we going to do?\n",
    "- Create a synthetic (artificial) dataset with NumPy\n",
    "- Create a synthetic dataset with a random error term\n",
    "- Create a synthetic dataset with unconsidered parameters\n",
    "- Create a synthetic dataset with Scikit-learn\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca79148-5ed3-46e6-8491-47e145c7c6b3",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "A synthetic dataset is a dataset of artificially created examples. These datasets are very useful for testing algorithms and our implementation, since we will be able to control the features of the dataset at all times.\n",
    "\n",
    "Similarly, since the influence of the training dataset and its cleaning, pre-processing, etc., are key to training ML models, when we are going to perform an implementation for the first time it would not be difficult to find multiple datasets with controlled features and, in particular, to be sure whether possible errors in the training are caused by our implementation or by the source data.\n",
    "\n",
    "Fill in the code of the following cells according to the instructions to create the different synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb48472-fd3c-402e-a0f1-6f37de0a39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79261e41-cb48-4c27-b2fb-82c08549eb06",
   "metadata": {},
   "source": [
    "## Task 1: Create a synthetic dataset with NumPy\n",
    "\n",
    "For this task we are going to create a synthetic dataset using NumPy’s functions.\n",
    "With this method we can completely control the features of the dataset.\n",
    "\n",
    "Recall the multiple linear regression equation and the dimensions of the vectors:\n",
    "\n",
    "$Y = X \\times \\Theta^T$\n",
    "\n",
    "m = nº of examples\n",
    "\n",
    "n = nº of features/coefficients\n",
    "\n",
    "$Y_{m \\times 1}$ (column vector)\n",
    "\n",
    "$X_{m \\times n}$ (2D matrix)\n",
    "\n",
    "$\\Theta_{1 \\times n}$ (row vector)\n",
    "\n",
    "*HINT:* Use the Numpy function np.random.random() for a random array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607cc1e5-5783-4419-9c8c-33b2726c6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the following arrays that define the original dataset\n",
    "\n",
    "# Choose some values for m and n (type: int)\n",
    "m = 0\n",
    "n = 0\n",
    "\n",
    "# X is a 2D m x n array of random nºs between -100 and 100\n",
    "# Use NumPy’s functions to generate an m x n array with random nºs between [0, 1)\n",
    "# Random Nº in the range [a, b): ndarray * (b - a) + a, where a = -100 and b = 100\n",
    "X = [...]\n",
    "\n",
    "# Insert the bias term b or X0 to parallelise the equation\n",
    "# Insert a 1. (float) column to the left of X with Numpy's insert function np.insert()\n",
    "X = X\n",
    "\n",
    "# Theta is a 1D 1 x n array that we can also implement as n x 1(column or row)\n",
    "# Generate it with n +1 random elements [0, 1) in order to add the bias term\n",
    "Theta = [...]\n",
    "\n",
    "# Compute Y by multiplying the vectors X and Theta with np.matmul()\n",
    "Y = [...]\n",
    "\n",
    "# Check the values and dimensions (form or \"shape\") of the arrays with the ndarray.shape property\n",
    "print('Theta to be estimated:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print('shape', 'shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d5b50-a811-4fe5-a7b7-f2cd26bf6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot X_1 vs Y in a Matplotlib 2D dot plot\n",
    "# X_1 is column nº 2 of X, the first column whose values are not all 1.\n",
    "# From now on, try to use labels for the axes and a title for the graph\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Your code here\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4a1c3-8318-4c53-8466-5b177fb497e6",
   "metadata": {},
   "source": [
    "Once implemented correctly, why don't you vary the m and n terms and check that you can create arrays of various dimensions?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79eb1ec-b79a-4379-b566-ead3b420a124",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 2: Create a synthetic dataset with a random error term\n",
    "\n",
    "We are now going to repeat the steps of the previous point, but adding a random error term to Y, to make a dataset with data that is not as accurate, more similar to a real situation, being able to control said error.\n",
    "\n",
    "*HINT:* Use the Numpy function np.uniform() for a value between the range +/- e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6854cfd-7062-4552-ac0c-36c2a0adbad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the following arrays that define the original dataset with a random error term\n",
    "\n",
    "# Choose some values for m and n (type: int)\n",
    "m = 0\n",
    "n = 0\n",
    "\n",
    "# X is a 2D m x n array of random nºs between -100 and 100\n",
    "# Use NumPy’s functions to generate an m x n array with random nºs between [0, 1)\n",
    "# Random Nº in the range [a, b): ndarray * (b - a) + a, where a = -100 and b = 100\n",
    "X = [...]\n",
    "\n",
    "# Insert the bias term b or X0 to parallelise the equation\n",
    "# Insert a 1. (float) column to the left of X with Numpy's insert function np.insert()\n",
    "\n",
    "# Theta is a 1D 1 x n array that we can also implement as n x 1 (row)\n",
    "# Generate it with n +1 random elements [0, 1) in order to add the bias term\n",
    "Theta = [...]\n",
    "\n",
    "# Compute Y by multiplying the vectors X and Theta with np.matmul()\n",
    "Y = [...]\n",
    "\n",
    "# From here, we add the error term e in percentage (0.1 = 10%, 0.25 = 25%, etc.)\n",
    "e = 0.1\n",
    "\n",
    "# In the following line, substitute “error term” for a term that represents a random number in the range +/- e (e.g. (+/- 10%)\n",
    "# Thus, the error term will be a percentage of +/- the error term over the original Y value\n",
    "# Remember that we must add an error to each Y between the positive and negative value of e, not add e directly\n",
    "Y_final = Y + Y * error_term\n",
    "\n",
    "# Check the values and dimensions (form or \"shape\") of the arrays with the ndarray.shape property\n",
    "print('Theta to be estimated:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print('shape', 'shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272a7f3-97d9-48d4-bc07-984b33147cf1",
   "metadata": {},
   "source": [
    "Vary the error term to check its effect on *Y_final*.\n",
    "\n",
    "*Do you dare to plot Y vs X and Y_final vs X to appreciate the error term?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08b1c9-5e07-4ca7-8d51-78cee0b90956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot X vs Y and X vs Y_final in a Matplotlib dot plot\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Your code here\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39502444-3083-42fb-85b4-edf3fbf6a33f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3: Create a synthetic dataset with unconsidered parameters\n",
    "\n",
    "Sometimes, with real-life datasets, it happens that our Y variable is influenced by multiple features, some of which we may not have considered. Imagine, e.g., a home appraisal, but there is some feature of the home which clients take into consideration, but we do not have that feature available in our training dataset.\n",
    "\n",
    "E.g.,the proximity to the nearest metro, bus, or suburban train stop, the time to the nearest highway exit, the modernity of the neighbourhood or the difference in municipal taxes compared to other nearby municipalities.\n",
    "\n",
    "In such cases, we want to compare our implementation or our models with models that take into account more or fewer features than actually affect the Y variable.\n",
    "\n",
    "Therefore, on such occasions a very useful dataset would be one that is comprised of multiple features (multiple columns of X), but whose columns are eventually reduced to a smaller number when training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73cc78-4bcd-4151-92d0-6c98a82c5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the following arrays that define the original dataset with a random error term\n",
    "\n",
    "# Choose some values for m and n (type: int)\n",
    "m = 0\n",
    "n = 0\n",
    "\n",
    "# X is a 2D m x n array of random nºs between -100 and 100\n",
    "# Use NumPy’s functions to generate an m x n array with random nºs between [0, 1)\n",
    "# Random Nº in the range [a, b): ndarray * (b - a) + a, where a = -100 and b = 100\n",
    "X = [...]\n",
    "\n",
    "# Insert the bias term b or X0 to parallelise the equation\n",
    "# Insert a 1. (float) column to the left of X with Numpy's insert function np.insert()\n",
    "X = X\n",
    "\n",
    "# Theta is a 1D 1 x n array that we can also implement as n x 1 (row)\n",
    "# Generate it with n +1 random elements [0, 1) in order to add the bias term\n",
    "Theta = [...]\n",
    "\n",
    "# Compute Y by multiplying the vectors X and Theta with np.matmul()\n",
    "Y = [...]\n",
    "\n",
    "# From here, we add the error term e in percentage (0.1 = 10%, 0.25 = 25%, etc.)\n",
    "e = 0.1\n",
    "\n",
    "# In the following line substitute \"error_term\" for a term that represents a random number in the range +/- e (i.e. +/- 10%)\n",
    "# Thus, the error term will be a percentage of +/- the error term over the original Y value\n",
    "Y = Y + Y * error_term\n",
    "\n",
    "# Finally, restrict the number of columns of X and Theta values to consider only the first n_final\n",
    "# You can use NumPy/Python slices for this\n"
    "n_final = 1"
    "\n","
    "n_final = 1\n",
    "\n",
    "Y_final = Y\n",
    "X_final = X[...]\n",
    "Theta_final = Theta[...]\n",
    "\n",
    "# Check the values and dimensions (form or \"shape\") of the arrays with the ndarray.shape property\n",
    "print('Theta to be estimated:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print('shape', 'shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cdbe0b-e49e-4706-902b-454b4433a1f9",
   "metadata": {},
   "source": [
    "## Task 4: Create a synthetic dataset with Scikit-learn\n",
    "\n",
    "Scikit-learn comes with several modules to provide datasets for development or evaluation. We commonly use synthetically generated datasets for development, and we use some of the more common datasets to evaluate and compare different algorithms and implementations, as we will see during the course.\n",
    "\n",
    "The dataset generation tools can be found in the documentation: [https://scikit-learn.org/stable/datasets/sample_generators.html] (https://scikit-learn.org/stable/datasets/sample_generators.html)\n",
    "\n",
    "Remember that each page of the documentation usually includes several notebooks with examples of their use.\n",
    "\n",
    "Review the documentation in detail, as you will be able to use these functions during the course for any dataset you need to download or generate synthetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f752a6-c2ff-4847-a61a-e43229eb1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the Scikit-learn functions to generate a synthetic dataset designed to solve a multivariate linear regression problem\n",
    "# Choose the correct function for this\n",
    "\n",
    "# Import the corresponding module\n",
    "from sklearn import [...]\n",
    "\n",
    "# Generate the dataset with the corresponding function and obtain the Theta or coefficients used to generate the dataset\n",
    "# This is usually done with the parameter coef=True\n",
    "# Remember to add the error/noise term\n",
    "X, Y, Theta = [...]\n",
    "\n",
    "# Check the values and dimensions (form or \"shape\") of the arrays with the ndarray.shape property\n",
    "print('Theta to be estimated:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print('shape', 'shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e900efc-1f1c-42df-87f4-352f6fd2c3e7",
   "metadata": {},
   "source": [
    "*What m and n will this dataset have?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ffd30b-af67-43eb-93fa-910b6caeccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Determine m and n of this dataset with the shape or size of the arrays\n",
    "m = [...]\n",
    "n = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2bd9ff-6726-4de5-b308-37c94f5e39a8",
   "metadata": {},
   "source": [
    "Repeat the steps in the previous cell to download a small sample dataset or "toy" intended to solve a multivariate linear regression problem.\n",
    "\n",
    "Toy dataset: [https://scikit-learn.org/stable/datasets/toy_dataset.html](https://scikit-learn.org/stable/datasets/toy_dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024392f-9416-4f7c-839a-2017a4de5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: : Repeat the steps in the previous cell to download a small sample dataset or "toy" intended to solve a multivariate linear regression problem\n",
    "# Choose one of the correct datasets for this"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
