{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9afd25-e3cb-4641-883a-a8e708e2a736",
   "metadata": {},
   "source": [
    "# Linear Regression: Synthetic dataset example\n",
    "M2U2 - Exercise 5\n",
    "\n",
    "## What are we going to do?\n",
    "- Use an automatically generated synthetic dataset to check our implementation\n",
    "- Train a multivariate linear regression ML model\n",
    "- Check the training evolution of the model\n",
    "- Evaluate a simple model\n",
    "- Make predictions about new future examples\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8adcb2-aeae-4431-98d0-3f157acf9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12947e67-26b6-448d-9714-5bfa36be3250",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creation of a synthetic dataset\n",
    "\n",
    "We are going to create a synthetic dataset to check our implementation.\n",
    "\n",
    "Following the methods that we have used in previous exercises, create a synthetic dataset using the NumPy method.\n",
    "\n",
    "Include a controllable error term in that dataset, but initialise it to 0, since to make the first implementation of this multivariate linear regression ML model we do not want any error in the data that could hide an error in our model.\n",
    "\n",
    "Afterwards, we will introduce an error term to check that our implementation can also train the model under these more realistic circumstances.\n",
    "\n",
    "### The bias or intercept term\n",
    "\n",
    "This time, we are going to generate the synthetic dataset with a small modification: we are going to add a first column of 1s to X, or a 1. (float) as the first value of the features of each example.\n",
    "\n",
    "Furthermore, since we have added one more feature n to the matrix X, we have also added one more feature or value to the vector $\\Theta$, so we now have n + 1 features.\n",
    "\n",
    "Why do we add this column, this new term or feature?\n",
    "\n",
    "Because this is the simplest way to implement the linear equation in a single linear algebra operation, i.e., to vectorise it.\n",
    "\n",
    "In this way, we thus convert $Y = m \\times X + b$ en $Y = X \\times \\Theta$, saving us an addition operation and implementing the equation in a single matrix multiplication operation.\n",
    "\n",
    "The term *b*, therefore, is incorporated as the first term of the vector $\\Theta$, which when multiplied by the first column of X, which has a value of 1 for all its rows, allows us to add said term *b* to each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87898f6d-d055-47e1-a732-ba32515bcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate a synthetic dataset in whatever way you choose, with error term initially set to 0\n",
    "\n",
    "m = 100\n",
    "n = 3\n",
    "\n",
    "# Create a matrix of random numbers in the interval [-1, 1)\n",
    "X = [...]\n",
    "# Insert a vector of 1s as the 1st column of X\n",
    "# Tips: np.insert(), np.ones(), index 0, axis 1...\n",
    "X = [...]\n",
    "\n",
    "# Generate a vector of random numbers in the interval [0, 1) of size n + 1 (to add the bias term)\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Añade al vector Y un término de error aleatorio en % (0.1 = 10%) inicializado a 0\n",
    "# Dicho término representa un error en +/- dicho porcentaje, p. ej., +/- 5%, +/- 10%, etc., no sólo a sumar\n",
    "# El porcentaje de error se calcula sobre Y, por lo tanto el error sería p. ej. el +3,14% de Y, -4,12% de Y...\n",
    "error = 0.\n",
    "\n",
    "Y = np.matmul(X, Theta_verd)\n",
    "Y = Y + [...] * error\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea2b0c-65c3-44fe-bd4a-7893e439c4ee",
   "metadata": {},
   "source": [
    "Fíjate en la operación de multiplicación matricial implementada: $Y = X \\times \\Theta$\n",
    "\n",
    "Comprueba las dimensiones de cada vector: X, Y, $\\Theta$.\n",
    "*¿Crees que es una operación posible según las reglas del álgebra lineal?*\n",
    "\n",
    "Si tienes dudas, puedes consultar la documentación de Numpy relativa a la función np.matmul.\n",
    "\n",
    "Comprueba el resultado, tal vez reduciendo el nº de ejemplos y características original, y asegúrate de que es un resultado correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9c1d5-c55b-4738-b6e7-a311bb352715",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "Copia del ejercicio anterior tu implementación de la función de coste y su optimización por gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a626cc6-67cb-477f-b624-0908ddd4bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia el código de tus funciones de coste y descenso de gradiente\n",
    "\n",
    "def cost_function(x, y, theta):\n",
    "    \"\"\" Computa la función de coste para el dataset y coeficientes considerados.\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los valores de las variables independientes de los ejemplos, de tamaño m x n + 1\n",
    "    y -- array 1D de Numpy con la variable dependiente/objetivo, de tamaño m x 1\n",
    "    theta -- array 1D de Numpy con los pesos de los coeficientes del modelo, de tamaño 1 x n + 1(vector fila)\n",
    "    \n",
    "    Devuelve:\n",
    "    j -- float con el coste para dicho array theta\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def gradient_descent(x, y, theta, alpha, e, iter_):\n",
    "    \"\"\" Entrena el modelo optimizando su función de coste por gradient descent\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los valores de las variables independientes de los ejemplos, de tamaño m x n + 1\n",
    "    y -- array 1D de Numpy con la variable dependiente/objetivo, de tamaño m x 1\n",
    "    theta -- array 1D de Numpy con los pesos de los coeficientes del modelo, de tamaño 1 x n + 1 (vector fila)\n",
    "    alpha -- float, ratio de entrenamiento\n",
    "    \n",
    "    Argumentos nombrados (keyword):\n",
    "    e -- float, diferencia mínima entre iteraciones para declarar que el entrenamiento ha convergido finalmente\n",
    "    iter_ -- int/float, nº de iteraciones\n",
    "    \n",
    "    Devuelve:\n",
    "    j_hist -- list/array con la evolución de la función de coste durante el entrenamiento, de tamaño nº de iteraciones que ha usado el modelo\n",
    "    theta -- array de Numpy con el valor de theta en la última iteración, de tamaño 1 x n + 1\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b83ca-7bdb-42e6-9320-7a0f3eeec93c",
   "metadata": {},
   "source": [
    "Vamos a utilizar dichas funciones para entrenar nuestro modelo de ML.\n",
    "\n",
    "Recordamos los pasos que vamos a seguir:\n",
    "- Iniciar $\\Theta$ con valores aleatorios\n",
    "- Optimizar $\\Theta$ reduciendo el coste asociado a cada iteración de sus valores\n",
    "- Cuando hayamos encontrado el valor mínimo de la función de coste, tomar su $\\Theta$ asociada como los coeficientes de nuestro modelo\n",
    "\n",
    "Por tanto, completa el código de la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fdc77-da49-471a-b986-73be8ec6d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena tu modelo de ML optimizando sus coeficientes Theta por gradient descent\n",
    "\n",
    "# Inicializa theta con n + 1 valores aleatorios\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "e = 1e-4\n",
    "iter_ = 1e5\n",
    "\n",
    "print('Hiper-parámetros a utilizar:')\n",
    "print('Alpha: {}, e: {}, nº máx. iter: {}'.format(alpha, e, iter_))\n",
    "\n",
    "t = time.time()\n",
    "j_hist, theta = gradient_descent([...])\n",
    "\n",
    "print('Tiempo de entrenamiento (s):', time.time() - t)\n",
    "\n",
    "# TODO: completar\n",
    "print('\\nÚltimos 10 valores de la función de coste')\n",
    "print(j_hist[...])\n",
    "print('\\Coste final:')\n",
    "print(j_hist[...])\n",
    "print('\\nTheta final:')\n",
    "print(theta)\n",
    "\n",
    "print('Valores verdaderos de Theta y diferencia con valores entrenados:')\n",
    "print(Theta_verd)\n",
    "print(theta - Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c814b-faf2-488b-add1-5448b5d3c793",
   "metadata": {},
   "source": [
    "Comprueba que no se ha modificado la $\\Theta$ inicial. Tu implementación debe copiar un nuevo objeto de Python en cada iteración y no modificarla durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df9748-858d-4ac8-b3b0-17140e921436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba que no se ha modificado la Theta inicial\n",
    "\n",
    "print('Theta inicial y theta final:')\n",
    "print(theta_ini)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50ac66-c917-4e73-a6d1-c7216938e9f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Comprobar el entrenamiento del modelo\n",
    "\n",
    "Para comprobar el entrenamiento del modelo, vamos a representar gráficamente la evolución de la función de coste, para comprobar que no ha habido ningún gran salto y que haya avanzado constantemente hacia un valor mínimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e993a2b-95ce-435e-a5e0-7aa5ab1ad898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title('Función de coste')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Coste')\n",
    "\n",
    "plt.plot([...])    # Completa los argumentos\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f2ca5-665f-4808-9bb0-ec212e033fd7",
   "metadata": {},
   "source": [
    "## Realizar predicciones\n",
    "\n",
    "Vamos a utilizar la $\\Theta$, el resultado de nuestro proceso de entrenamiento del modelo, para realizar predicciones sobre nuevos ejemplos que llegaran en el futuro.\n",
    "\n",
    "Generaremos un nuevo conjunto de datos X siguiendo los mismos pasos que hemos seguido anteriormente. Por tanto, si X tiene el mismo nº de características (n + 1) y sus valores están en el mismo rango de la X generada previamente, se comportarán igual que los datos usados para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c39c63-05a6-4c85-89e5-16187c4a59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realiza predicciones usando la theta calculada\n",
    "\n",
    "# Genera una nueva matriz X con nuevos ejemplos. Usa el mismo nº de características y el mismo rango de valores\n",
    "# aleatorios, pero un nº de ejemplos menor (p. ej., 25% del original)\n",
    "# Recuerda añadir el término bias, o una primera columna de 1s a la matriz, de tamaño m x n + 1\n",
    "X_pred = [...]\n",
    "\n",
    "# Calcula las predicciones para dichos nuevos datos\n",
    "y_pred = [...]    # Pista: de nuevo, matmul\n",
    "\n",
    "print('Predicciones:')\n",
    "print(y_pred)    # Puedes imprimir todo el vector o sólo los primeros valores, si es demasiado largo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e231f49-9179-411c-b34e-4548f3be6f01",
   "metadata": {},
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "Para evaluar el modelo tenemos varias opciones. En este punto, vamos a hacer una evaluación más simple, rápida e informal del mismo. En siguientes módulos del curso veremos cómo evaluar nuestros modelos de una forma más formal y precisa.\n",
    "\n",
    "Vamos a hacer una evaluación gráfica, para comprobar simplemente que nuestra implementación funciona como esperamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33bd75-c4a1-41b1-b363-d91333bacb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente los residuos entre la Y inicial y la Y predicha para los mismos ejemplos\n",
    "\n",
    "# Realiza predicciones para cada valor de la X original con la theta entrenada por el modelo\n",
    "Y_pred = [...]\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title('Dataset original y predicciones')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Residuos')\n",
    "\n",
    "# Calcula los residuos para cada ejemplo\n",
    "# Recuerda que son la diferencia en valor absoluto entre la Y real y la Y predicha para cada ejemplo\n",
    "residuos = [...]\n",
    "\n",
    "# Usa una gráfica con series diferentes: Y de entrenamiento, Y predicha y residuos\n",
    "# Usa una gráfica de puntos para la Y de entrenamiento, de línea para la Y predicha y de barra para los residuos, superpuestas\n",
    "plt.scatter([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807967f-7d35-456b-8cf7-a76e25bbc041",
   "metadata": {},
   "source": [
    "Si nuestra implementación es correcta, nuestro modelo debe haber podido entrenarse correctamente y tener unos resíduos prácticamente nulos, una diferencia prácticamente nula entre los resultados originales (Y) y los resultados que calcularía nuestro modelo.\n",
    "\n",
    "Sin embargo, como recordamos, en el primer punto hemos creado un dataset con el término de error a 0. Por tanto, cada valor de Y no tiene ninguna diferencia o variación aleatoria sobre su valor real.\n",
    "\n",
    "En la vida real, sea porque no hemos tenido en cuenta todas las características que afectarían a nuestra variable objetivo, sea porque los datos contienen algún pequeño error, o sea porque, por lo general, los datos no siguen un comportamiento completamente preciso, siempre tendremos algún término de error, más o menos aleatorio.\n",
    "\n",
    "Por tanto, *¿y si vuelves a la primera celda y modificas tu término de error, y ejecutas de nuevo las siguientes para entrenar y evaluar un nuevo modelo de regresión lineal sobre datos más parecidos a la realidad?*\n",
    "\n",
    "Comprueba de dicha forma la robustez de tu implementación."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
