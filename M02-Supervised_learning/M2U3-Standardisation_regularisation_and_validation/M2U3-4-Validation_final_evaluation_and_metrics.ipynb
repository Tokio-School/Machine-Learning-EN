{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99297ac-4801-4c79-a2fa-901355a5801c",
   "metadata": {},
   "source": [
    "# Linear Regression: Validation, final evaluation, and metrics\n",
    "M2U3 - Exercise 4\n",
    "\n",
    "## What are we going to do?\n",
    "- Create a synthetic dataset for multivariate linear regression\n",
    "- Preprocess the data\n",
    "- We will train the model on the training subset and check its suitability\n",
    "- We will find the optimal *lambda* hyperparameter for the validation subset\n",
    "- We will evaluate the model on the test subset\n",
    "- We will make predictions about new future examples\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d2b23-f655-4774-b2b6-3033d0267eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6445a2e-fe04-4a8b-ba15-768cc351d1af",
   "metadata": {},
   "source": [
    "## Create a synthetic dataset for linear regression\n",
    "\n",
    "We will start, as usual, by creating a synthetic dataset for this exercise.\n",
    "\n",
    "This time, for the error term, use a non-symmetric range, different from [-1, 1], such as [-a, b], with parameters *a* and *b* that you can control. In this way we can modify this distribution at later points to force a greater difference between the training and validation subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39806ebb-3466-4adb-aa59-8b4d50a90f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate a synthetic dataset manually, with a bias term and an error term\n",
    "\n",
    "m = 1000\n",
    "n = 3\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_true = [...]\n",
    "\n",
    "error = 0.2\n",
    "\n",
    "Y = [...]\n",
    "\n",
    "# Check the values and dimensions of the vectors\n",
    "print('Theta to be estimated and its dimensions:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b3e08-c416-451b-addd-c5e1aae0c95d",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "We will preprocess the data completely, to leave it ready to train the model.\n",
    "\n",
    "To preprocess the data, we will follow the steps below:\n",
    "- Randomly rearrange the data.\n",
    "- Normalise the data.\n",
    "- Divide the dataset into training, validation, and test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e736d3-b931-4a7b-8fd2-01e1a5aeb615",
   "metadata": {},
   "source": [
    "### Randomly rearrange the dataset\n",
    "\n",
    "This time we are going to use a synthetic dataset created using random data. Therefore, it will not be necessary to rearrange the data, as it is already randomized and disorganized by default.\n",
    "\n",
    "However, we may often encounter real datasets whose data has a certain order or pattern, which can confound our training.\n",
    "\n",
    "Therefore, before starting to process the data, the first thing we need to do is to randomly reorder it, especially before splitting it into training, validation, and test subsets.\n",
    "\n",
    "*Note*: Very important! Remember to always reorder the *X* and *Y* examples and results in the same order, so that each example is assigned the same result before and after reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d872e2-2c2c-426c-a8c8-ac367323ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Randomly reorder the dataset\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Use an initial random state of 42, in order to maintain reproducibility\n",
    "print('Reorder X and Y:')\n",
    "X, Y = [...]\n",
    "\n",
    "print('First 10 rows and 5 columns of X and Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensions of X and Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569a638-eabc-498a-8c8f-bc80b33f1784",
   "metadata": {},
   "source": [
    "Check that *X* and *Y* have the correct dimensions and a different order than before.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3297962-8236-4036-917e-c3019db5c0de",
   "metadata": {},
   "source": [
    "## Normalise the dataset\n",
    "\n",
    "Once the data has been randomly reordered, we will proceed with the normalisation of the *X* examples dataset.\n",
    "\n",
    "To do this, copy the code cells from the previous exercises to normalise it.\n",
    "\n",
    "*Nota*: En ejercicios pasados usábamos 2 celdas de código diferentes, una para definir la función de normalización y otra para normalizar el dataset. Puedes combinar ambas celdas en una para guardar dicho preprocesamiento en una celda reutilizable en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ceb351-1296-4c46-bfb4-c17b66dc896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "def normalize(x, mu=None, std=None):\n",
    "    \"\"\" Normaliza un dataset con ejemplos X\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los ejemplos, sin término de bias\n",
    "    mu -- vector 1D de Numpy con la media de cada característica/columna\n",
    "    std -- vector 1D de Numpy con la desviación típica de cada característica/columna\n",
    "    \n",
    "    Devuelve:\n",
    "    x_norm -- ndarray 2D con los ejemplos, con sus características normalizadas\n",
    "    mu, std -- si mu y std son None, calcula y devuelve dichos parámetros. Si no, usa dichos parámetros para normalizar x sin devolverlos\n",
    "    \"\"\"\n",
    "    return [...]\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original (primeras 10 filas y columnas):')\n",
    "print(X[:10, :10])\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5baf16d-a9c5-4fea-a90c-491c328bb84c",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento, validación y test\n",
    "\n",
    "Por último, vamos a dividir el dataset en los 3 subsets a utilizar.\n",
    "\n",
    "Para ello, vamos a usar en esta ocasión un ratio de 60%/20%/20%, ya que partimos de 1000 ejemplos.\n",
    "Como decíamos, para un nº de ejemplos diferente, podemos modificar el ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7ce09-47f7-4179-abcb-2ca6333f3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 3 subsets según los ratios indicados\n",
    "\n",
    "ratio = [60,20,20]\n",
    "print('Ratio:\\n', ratio, ratio[0] + ratio[1] + ratio[2])\n",
    "\n",
    "# Calcula los índices de corte para X e Y\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r = [0, 0]\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_val, X_test = [...]\n",
    "Y_train, Y_val, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e23119-bc3d-41d4-9b54-214b818660f4",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial sobre el subset de entrenamiento\n",
    "\n",
    "Antes de comenzar a optimizar el hiper-parámetro *lambda*, vamos a entrenar un modelo inicial sin regularización sobre el subset de entrenamiento, para comprobar su rendimiento e idoneidad, y estar seguros que tiene sentido entrenar un modelo de regresión lineal multivariable sobre dicho dataset, ya que las características podrían no ser las adecuadas, haber una baja relación entre ellas, no seguir una relación lineal, etc.\n",
    "\n",
    "Para ello, vamos a seguir los siguientes pasos:\n",
    "- Entrenar un modelo inicial, sin regularización, con *lambda* a 0.\n",
    "- Representar el histórico de la función de coste para comprobar su evolución.\n",
    "- Reentrenar el modelo si es necesario, p. ej. variando el ratio de aprendizaje *alpha*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cdeeb-b962-45e3-bd5c-72551c65cd40",
   "metadata": {},
   "source": [
    "Copia las celdas de ejercicios anteriores donde implementabas las funciones de coste y gradient descent regularizadas, y copia la celda donde entrenabas el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948972f-ed3e-4400-99b3-6bc6b34c52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia las celdas con las funciones de coste y gradient descent regularizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee29de0-a7d9-44d4-a6a8-b681ad2d3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda donde entrenamos el modelo\n",
    "# Entrena tu modelo sobre el subset de entrenamiento sin regularizar y obtén el coste final y el histórico de su evolución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b0c09-3c4a-4629-b971-14f229defe50",
   "metadata": {},
   "source": [
    "De la misma forma que hacíamos antes, comprueba el entrenamiento del modelo, representando gráficamente la evolución de la función de coste según el nº de iteraciones, copiando la celda de código correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e34e6f-140a-48a4-9b7c-f1a05d957ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c962d837-1c0f-44ec-b480-6d1756769ebc",
   "metadata": {},
   "source": [
    "Como decíamos antes, revisa el entrenamiento de tu modelo y modifica algún parámetro si es necesario para reentrenarlo, buscando que tenga un buen rendimiento: el ratio de aprendizaje, el punto de convergencia, el nº máx. de iteraciones, etc., excepto el parámetro de regularización *lambda*, que debe estar a 0.\n",
    "\n",
    "*Nota*: Este punto es importante, puesto que por lo general, estos hiper-parámetros serán los mismos que utilizaremos para lo que resta de la optimización del modelo, por lo que ahora es el momento de encontrar los valores idóneos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb720a0c-39e7-4c2e-8590-1751eb7a8e85",
   "metadata": {},
   "source": [
    "### Comprobar si existe desviación o sobreajuste, *bias* o *varianza*\n",
    "\n",
    "Hay un test que podemos hacer rápidamente para comprobar si nuestro modelo inicial sufre claramente de desviación, varianza, o tiene un funcionamiento más o menos aceptable.\n",
    "\n",
    "Vamos a representar gráficamente la evolución de la función de coste de 2 modelos, uno entrenado sobre los primeros *n* ejemplos del subset de entrenamiento y otro entrenado sobre los primeros *n* ejemplos del subset de validación.\n",
    "\n",
    "Puesto que el subset de entrenamiento y el subset de validación no tienen el mismo tamaño, usa únicamente el mismo nº de ejemplos para este subset que ejemplos totales tenga el de validación.\n",
    "\n",
    "Para ello entrena 2 modelos en igualdad de condiciones, copiando de nuevo las celdas de código correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415fa4e-9622-4a44-92b8-e801775128cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Establece una theta_ini e hiper-parámetros comunes a ambos modelos, para entrenarlos en igualdad de condiciones\n",
    "\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "iter_ = 1e3\n",
    "\n",
    "print('Hiper-arámetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afa142-838d-4bb6-a666-fd9da0d40343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo sin regularización sobre los n primeros valores de X_train, donde n es el nº de\n",
    "# ejemplos disponibles en X_val\n",
    "# Usa j_hist_train y theta_train como nombres de variables para distinguirlos del otro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294b17e-4a6b-4482-b44e-8523c31a4c38",
   "metadata": {},
   "source": [
    "*Nota*: Comprueba que *theta_ini* no se ha modificado, o modifica tu código para que ambos modelos usen la misma *theta_ini*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037ce66-0c05-41b0-8c7b-6123d8c8c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Del mismo modo, entrena un modelo sin regularización sobre X_val con los mismos parámetros\n",
    "# Recuerda usar j_hist_val y theta_val como nobmres de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c039e-b4b2-4070-b525-6df346df468e",
   "metadata": {},
   "source": [
    "Ahora representa gráficamente ambas evoluciones sobre la misma gráfica, con colores diferentes, para poder compararlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da673f-623f-4bb9-805e-24f299e91e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa en una gráfica de líneas las evoluciones del coste en ambos datasets para compararlas\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "# Usa colores diferentes para ambas series, e indica una leyenda para distinguirlos\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b09e13-f75e-472c-9d99-3a58e137219e",
   "metadata": {},
   "source": [
    "Con un dataset sintético aleatorio es difícil que se diera sobre-ajuste, ya que los datos originales seguirán el mismo patrón, pero de esta forma podríamos apreciar dichos problemas de la siguiente forma:\n",
    "\n",
    "- Si el coste final en ambos subsets es alto, puede haber un problema de desviación o *bias*.\n",
    "- Si el coste final en ambos subsets es muy diferente entre sí, puede haber un problema de sobreajuste o *varianza*, especialmente cuando el coste en el subset de entrenamiento es bastante inferior a en el subset de validación,\n",
    "\n",
    "Recordamos qué significaban la desviación y sobre-ajuste:\n",
    "- La desviación se produce cuando el modelo no puede ajustar suficientemente bien la curva del dataset, sea porque no son las características correctas (o faltarían otras), sea porque los datos tienen demasiado error, o sea porque el modelo sigue una relación distinta o sea demasiado simple.\n",
    "- El sobreajuste se produce cuando el modelo ajusta muy bien la curva del dataset, demasiado bien, demasiado ajustada a los ejemplos sobre los que se ha entrenado, y cuando tiene que predecir sobre nuevos resultados no lo hace correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228ba68-fb7c-459a-9d0f-e681a9594a68",
   "metadata": {},
   "source": [
    "### Comprobar la idoneidad del modelo\n",
    "\n",
    "Como decíamos, otra razón para entrenar un modelo inicial es comprobar si tiene sentido entrenar un modelo de regresión lineal multivariable sobre dicho dataset.\n",
    "\n",
    "Si vemos que el modelo sufre de sobreajuste, siempre podemos corregirla con la regularización. Sin embargo, si vemos que sufre de una alta desviación, i.e. que el coste final es muy alto, puede que nuestro tipo de modelo o las características escogidas no sean idóneas para este problema.\n",
    "\n",
    "En este caso, hemos comprobado que el error es suficientemente bajo para que resulte prometedor continuar entrenando dicho modelo de regresión lineal multivariable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94efa4-9bd6-410f-b921-d0bec64d1dd2",
   "metadata": {},
   "source": [
    "## Hallar el hiper-parámetro *lambda* óptimo sobre el subset de validación\n",
    "\n",
    "Ahora, para conseguir hallar la *lambda* óptima, vamos a entrenar un modelo diferente por cada valor de *lambda* a considerar, sobre el subset de entrenamiento, y comprobar su precisión sobre el subset de validación.\n",
    "\n",
    "Vamos a representar gráficamente el error o coste final de cada modelo vs el valor de *lambda* usado, para ver qué modelo tiene un error o coste menor en el subset de validación.\n",
    "\n",
    "De esta forma, entrenamos todos los modelos sobre el mismo subset y en igualdad de condiciones (excepto *lambda*), y los evaluamos en un subset de datos que no han visto previamente, que no hemos usado para entrenarlos.\n",
    "\n",
    "El subset de validación, por tanto, no se usa para entrenar el modelo, sino sólo para evaluar el valor de *lambda* óptimo. Excepto en el punto anterior, donde hemos hecho una evaluación inicial rápida sobre la posible aparición de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd793c-bc7e-4e69-9826-23498fddcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente sobre X_train y evalúalo sobre X_val\n",
    "\n",
    "lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "# BONUS: Genera un array de lambdas con 10 valores en una escala logarítmica entre 10^-3 y 10, alternando entre valores cuyo primer decimal no-cero es un 1 y un 3, como esta lista\n",
    "\n",
    "# Completa el código para entrenar un modelo diferente para cada valor de lambda sobre X_train\n",
    "# Almacena su theta y error/coste final\n",
    "# Posteriormente, evalúa su coste total en el subset de validación\n",
    "\n",
    "# Almacena dicha información en los siguientes arrays, del mismo tamaño que el de lambdas\n",
    "j_train = [...]\n",
    "j_val = [...]\n",
    "theta_val = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7788b-7d4b-4ce7-a715-565d86aebd66",
   "metadata": {},
   "source": [
    "Una vez entrenados todos los modelos, representa en una gráfica de líneas su coste final sobre el subset de entrenamiento y el coste final sobre el de validación vs el valor de *lambda* utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2871a-8f2c-4593-84e4-107a2be2c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completa con tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3216c6-47d6-4b40-a8b4-1ec094f0a8f7",
   "metadata": {},
   "source": [
    "Una vez representados dichos errores finales, podríamos elegir automáticamente el modelo con el valor de *lambda* óptimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8b282-aee5-41a5-ae16-4e713d172003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge el modelo y el valor de lambda óptimos, con el menor error sobre el subset de validación\n",
    "\n",
    "# Itera sobre la  theta y lambda de todos los modelos y escoge el de menor coste en el subset de validación\n",
    "\n",
    "j_final = [...]\n",
    "theta_final = [...]\n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4f7a4-caaf-4e1c-b2ef-ff8cedea8881",
   "metadata": {},
   "source": [
    "Una vez implementados todos los pasos anteriores, tenemos nuestro modelo entrenado y sus hiper-parámetros optimizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555a61a-22f0-4e65-9646-d6a5ba2b9210",
   "metadata": {},
   "source": [
    "## Evaluar el modelo finalmente sobre el subset de test\n",
    "\n",
    "Finalmente, hemos encontrado nuestros coeficientes *theta* e hiper-parámetro *lambda* óptimos, por lo que ya disponemos de un modelo entrenado y listo para ser usado.\n",
    "\n",
    "Sin embargo, aunque hemos calculado su error o coste final sobre el subset de validación, hemos usado dicho subset para escoger el modelo o para \"terminar de entrenarlo\". Por tanto, no hemos comprobado todavía cómo funcionará este modelo sobre datos que no ha visto nunca antes.\n",
    "\n",
    "Para ello, vamos a evaluarlo finalmente sobre el subset de test, sobre un subset que no hemos utilizado aún ni para entrenar el modelo ni para escoger sus hiper-parámetros. Un subset separado que el entrenamiento del modelo no ha visto aún.\n",
    "\n",
    "Por tanto, vamos a calcular el error o coste total sobre el subset de test y comprobar gráficamente los residuos del modelo sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7ab30-bc8b-4a48-83be-fdaffad5bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error del modelo sobre el subset de test usando la función de coste con las correspondientes\n",
    "# theta y lambda\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79b916-6359-4d68-b4ec-79175145cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones del modelo sobre el subset de test, sus resíduos y represéntalos\n",
    "\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5fffa-6f8e-4c90-ba0b-87d178f663c4",
   "metadata": {},
   "source": [
    "De esta forma podemos hacernos una idea más real sobre la precisión de nuestro modelo y cómo se comportará con nuevos ejemplos en el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e93c93-b0e0-4f8f-afd6-e3e806fb55ea",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestro modelo ya entrenado, optimizado y evaluado, lo único que nos queda es ponerlo en funcionamiento realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d7548-a5b0-4e89-ba76-3f7a61f09a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias y error aleatorio\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas originales\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "Y_pred = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda6132-a3cd-4929-a8b5-3b6e176ee48a",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos con Scikit-learn\n",
    "\n",
    "Para acabar, busca y utiliza las funciones disponibles en Scikit-learn para preprocesar los datos:\n",
    "1. [Reordenando aleatoriamente](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html?highlight=shuffle#sklearn.utils.shuffle)\n",
    "1. [Normalizando/escalando](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling)\n",
    "1. [Dividiendo los datos en los 3 subsets correspondientes](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=split#sklearn.model_selection.train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa80db3-5c42-4e02-b3f7-b15413bcf832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Utiliza las funciones de Scikit-learn para reordenar aleatoriamente, normalizar y dividir los datos en los subsets de entrenamiento, validación y test\n",
    "# Utiliza la X original en lugar de X_norm\n",
    "\n",
    "X_reord = [...]\n",
    "\n",
    "X_escalada = [...]\n",
    "\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9623f78-2089-4020-8444-f12f06c14633",
   "metadata": {},
   "source": [
    "*BONUS*: ¿Puedes corregir tu código para conseguir aplicar dichas operaciones estándar en las menos líneas posibles y dejarlo listo para reutilizarlo en cada ocasión?"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
