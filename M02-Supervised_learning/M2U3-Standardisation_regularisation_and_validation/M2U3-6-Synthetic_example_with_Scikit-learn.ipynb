{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9426a6-87f3-40a6-8c5f-941f0a4be60d",
   "metadata": {},
   "source": [
    "# Linear Regression: Synthetic example with Scikit-learn\n",
    "M2U3 - Exercise 6\n",
    "\n",
    "## What are we going to do?\n",
    "- We will solve a multivariate linear regression model using Scikit-learn\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa052fc-51d9-40b1-be66-4effb2edae9f",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Once we developed a hands-on implementation of the multivariate linear regression algorithm with Numpy exclusively, we have been able to see in depth the steps to follow, how the internal mathematical algorithm works, and how all the hyperparameters affect it.\n",
    "\n",
    "Having a good understanding of how these ML models work, let's see how to use them with the functions of the Scikit-learn ML framework.\n",
    "\n",
    "In this exercise you will have a blank template with the steps we have followed in previous exercises, which you will have to complete with your code following those steps, but this time using Scikit-learn methods.\n",
    "\n",
    "In each cell we will suggest a Scikit-learn function that you can use. We won't give you more information about it here, because we want you to look it up for yourself in the documentation: how it works, the algorithms it implements (some of them will be slightly different from the ones we have seen in the course, don't worry as the important thing is the base), arguments, examples, etc.\n",
    "\n",
    "It sounds like a truism, but I'm sure you will agree with us that the ability to find relevant information in the documentation at all times is extremely important, and it can often cost us a little more than it should :).\n",
    "\n",
    "Also take the opportunity to dive deeper into the documentation and discover interesting aspects of the framework. We will continue to work with it in subsequent exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3107a3-7a0f-485e-a2c4-35203f3cf59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all the necessary modules into this cell\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524eb8a5-4cfe-45f2-86de-fa7468cd3674",
   "metadata": {},
   "source": [
    "## Create a synthetic dataset for linear regression\n",
    "\n",
    "- Add a modifiable bias and error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14a0e9-879f-4521-b42f-00cc29bb34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a synthetic dataset for linear regression with Scikit-learn\n",
    "# You can use the sklearn.datasets.make_regression() function\n",
    "# Remember to always use a given random start state to maintain reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9628d70-ce18-48c5-bb29-c4f9e13ee149",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "- Randomly reorder the data..\n",
    "- Normalise the data..\n",
    "- Dvide the data into training and test subsets.\n",
    "\n",
    "*Note*: Why did we use only 2 training and test subsets this time, with no validation subset? Because we will use *k-fold* for our cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44e3fe-a738-499d-b60b-0d0064fe2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Randomly reorder the data\n",
    "# You can use the sklearn.utils.shuffle() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8d39a-37c7-4ed3-a2f3-11718fbfc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalise the examples\n",
    "# You can use the sklearn.preprocessing.StandardScaler() class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b5894-1ecd-4de6-b358-428ed42fb854",
   "metadata": {},
   "source": [
    "*Note*: This scaling is equivalent to the basic normalisation we have seen throughout the course. Another more convenient but more complex to comprehend normalisation for more advanced models would be the one implemented in *sklearn.preprocessing.normalize*.\n",
    "\n",
    "You can find all the available preprocessing classes and functions here: [Sklearn docs: 6.3. Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "\n",
    "And a graphical comparison: [Compare the effect of different scalers on data with outliers](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eec2eb-d249-46ad-a9a2-30a55b7c8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide the dataset into training and test subsets\n",
    "# You can use the sklearn.model_selection.train_test_split() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db3368-6f2d-4cb2-82da-cb02adacf13f",
   "metadata": {},
   "source": [
    "## Train an initial model\n",
    "\n",
    "- Train an initial model on the training subset without regularisation.\n",
    "- Test the suitability of the model.\n",
    "- Check if it suffers from deviation or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ab79a-eec7-4c38-951c-995309a6105a",
   "metadata": {},
   "source": [
    "To train a simple multivariate linear regression model, you can use the [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) class\n",
    "\n",
    "You can consult a complete training example: [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a136bc-35fb-4d46-959a-7bcd18fe3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a baseline linear regression model on the training subset without regularisation\n",
    "# Adjust the intercept/bias term and do not normalise the features, as we have already normalised them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb8363-0fd5-4950-9862-507ea4f6065a",
   "metadata": {},
   "source": [
    "Comprueba la idoneidad del modelo aplicado a este dataset. Para ello puedes usar:\n",
    "- El coeficiente de determinación R^2 del método [LinearRegression.score()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score)\n",
    "- La función [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) (permite devolver el MSE o RMSE)\n",
    "- Otras [métricas para regresión](https://scikit-learn.org/stable/modules/classes.html#regression-metrics)\n",
    "\n",
    "Prueba varios de los métodos para conocerlos mejor y ver sus posibles diferencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c124b483-05c4-4452-b5d2-a173c10b400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba la idoneidad del modelo evaluándolo sobre el set de test\n",
    "# Comprueba 3 de las métricas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c63d5-d604-4fde-aea1-db964f92b837",
   "metadata": {},
   "source": [
    "Para comprobar si pudiera existir desviación o sobreajuste, podemos calcular p. ej. el RMSE sobre las predicciones del subset de entrenamiento y sobre las del de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48c4a0-86c1-4c95-a816-57d877cf2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba si la evaluación sobre ambos subsets es similar con el RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe51468-adab-4332-b4ce-cd37dc7629c9",
   "metadata": {},
   "source": [
    "## Hallar la regularización óptima por validación cruzada o *k-fold*\n",
    "\n",
    "- Entrena un modelo por cada valor de regularización a considerar.\n",
    "- Entrénalos y evalúalos sobre una divisón del subset de entrenamiento por K-fold.\n",
    "- Escoge el modelo y su regularización óptimos.\n",
    "\n",
    "Ahora vamos a usar un algoritmo de regresión lineal más complejo, la clase [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) que nos permite establecer un parámetro de regularización L2.\n",
    "\n",
    "En esta función, el argumento de regularización se denomina *alpha*, aunque no debemos confundirlo con el ratio de aprendizaje.\n",
    "\n",
    "La regularización que hemos visto durante el curso es la que implementan la mayoría de algoritmos de Scikit-learn, siendo su denominación común \"L2\" o \"L2-norm\" en inglés.\n",
    "\n",
    "Considera unos parámetros de regularización L2 en el rango logarítmico: 0.1, 0.01, 0.001, 0.0001, etc.\n",
    "\n",
    "Puedes guiarte por este enlace: [K-fold](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740c1c0-a47c-4e99-8aac-90dda330b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo diferente por cada alpha sobre un fold de K-fold diferente\n",
    "\n",
    "# Usa una función de Numpy para crear un espacio logarítmico de >5 valores entre [0, 1e-3]\n",
    "alphas = [...]\n",
    "\n",
    "# Crea k splits de K-fold\n",
    "kfolds = [...]\n",
    "\n",
    "# Itera sobre los splits para tus modelos y evalúalos en el subset de CV generado\n",
    "linear_models = []\n",
    "best_model = None\n",
    "for train, cv in kfolds.split(X):\n",
    "    # Entrena un modelo sobre el subset train\n",
    "    # Recuerda establecer el parámetro alpha/regularización correspondiente, ajustar el bias y no normalizar\n",
    "    # Evalúalo sobre el subset de CV usando su método model.score()\n",
    "    # Guarda el modelo con el mejor score en la variable best_model y muestra el alpha del mejor modelo\n",
    "    alpha = [...]\n",
    "    print('Regularización L2:', alpha)\n",
    "    \n",
    "    model = [...]\n",
    "    \n",
    "    linear_models.append(model)\n",
    "    \n",
    "    # Si el modelo es mejor que el mejor modelo hasta ahora...\n",
    "    best_model = [...]\n",
    "    \n",
    "    print('Regularización L2 del mejor modelo hasta ahora:', alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f97d9f-170e-44ff-917e-6a81e5186827",
   "metadata": {},
   "source": [
    "## Evaluar el modelo finalmente sobre el subset de test\n",
    "\n",
    "- Muestra los coeficientes e intercept del mejor modelo.\n",
    "- Evalúa el mejor modelo sobre el subset de test inicial.\n",
    "- Calcula los resíduos sobre el subset de test y represéntalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a4a0c4-24f4-44cc-99a1-bbee993fbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el mejor modelo sobre el subset de test inicial\n",
    "\n",
    "# Muestra los coeficientes e intercept del mejor modelo entrenado\n",
    "print('Coeficientes de intercept del modelo entrenado:')\n",
    "print([...])    # Muestra el intercept como el primer coeficiente\n",
    "\n",
    "# Realiza las predicciones sobre el subset de test\n",
    "y_test_pred = [...]\n",
    "\n",
    "# Calcula las métricas de evaluación del modelo: RMSE y coeficiente de determinación R^2\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "\n",
    "print('Raíz del error cuadrático medio (RMSE): %.2f' % rmse)\n",
    "print('Coeficiente de determinación: %.2f' % r2_score)\n",
    "\n",
    "# Calcula los resíduos sobre el subset de test\n",
    "residuals = [...]\n",
    "\n",
    "# Represéntalos gráficamente\n",
    "plt.figure(1)\n",
    "\n",
    "# Completa con tu código\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73c084-040e-4cdb-8bb0-ec6dabcd0f0e",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "- Genera un nuevo ejemplo siguiendo el mismo patrón del dataset original.\n",
    "- Normaliza sus características.\n",
    "- Genera una predicción para dicho ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113c4eb-6a5b-4a22-963b-7f57bc3611b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realiza predicciones sobre un nuevo ejemplo creado manualmente\n",
    "\n",
    "# Crea el nuevo ejemplo\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
