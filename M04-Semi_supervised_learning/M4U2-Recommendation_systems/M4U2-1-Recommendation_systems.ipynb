{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5ab6b9-f3bd-41e8-8c75-952424a55a6d",
   "metadata": {},
   "source": [
    "# Recommender systems: Collaborative filters\n",
    "M4U2 - Exercise 1\n",
    "\n",
    "## What are we going to do?\n",
    "- We will investigate the collaborative filtering approach\n",
    "- We will create a dataset to be solved by recommender systems\n",
    "- We will implement the cost and gradient descent functions\n",
    "- We will train a recommendation model using collaborative filters\n",
    "- We will make predictions of recommendations\n",
    "- We will retrain the model by incorporating new valuations\n",
    "- We will recommend similar examples to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230b199-0f17-4353-8da2-8d07822a97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use this cell to import all the necessary libraries\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e17d9-1823-40a8-86e1-1c28832c52f3",
   "metadata": {},
   "source": [
    "# Create a synthetic dataset\n",
    "\n",
    "A common example is film recommendations on a video streaming portal. In this case, a dataset would have these features e.g.:\n",
    "- *m*: Nº of films.\n",
    "- *n*: Number of features of each film and coefficients of each user for them.\n",
    "- $n_u$: Nº of portal users.\n",
    "- $n_ru$ and $n_r$: Percentage of ratings for each film and total number of ratings, known in advance.\n",
    "- *X*: 2D matrix of features for each film, size (no of films, no of features).\n",
    "- $\\Theta$: 2D matrix of coefficients of each user for each film, size (nº of features, nº of users).\n",
    "- *Y*: 2D Matrix of ratings of each user for each film, size (nº of films, nº of users).\n",
    "\n",
    "We are going to create a synthetic dataset as usual, but this time focused on recommender systems, with some differences compared to linear regression:\n",
    "- The predictor or independent features *X* (size (*m*, *n* + 1)), which represents the features of each example, **are not known in advance**.\n",
    "- The vector $\\Theta$ (*Theta*) is 2D (size (*n* + 1, $n_u$)), since it now represents the coefficients of the features for each user. **Again, it is not known in advance**.\n",
    "- The vector *Y* is 2D (size (*m*, $n_u$)), as it now represents each user's rating for each example.\n",
    "- The vector *Y* will contain both the \"real\" ratings given by each user for each film they have rated, and, at the end of the training, their predicted ratings for recommending one film or another.\n",
    "- *R* will be a \"mask\" matrix over *Y*, used to indicate which ratings of *Y* are real and issued by a user, and therefore only those used to train the model.\n",
    "\n",
    "To have at hand, we leave you this quick reference table with the size of each matrix:\n",
    "- $X (m, n + 1)$\n",
    "- $\\Theta (n + 1, n_u)$\n",
    "- $Y (m, n_u)$\n",
    "\n",
    "In order not to complicate the implementation further, we will not preprocess the data in this case.\n",
    "\n",
    "Follow the instructions to generate a dataset with the necessary features to be solved by a collaborative filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613876f6-32c8-4675-9761-d20efcd76258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a dataset with the necessary features for a recommender system\n",
    "# Remember that you can go back to this cell and modify the features of the dataset at any time\n",
    "\n",
    "m = 1000    # Nº of examples\n",
    "n = 4    # Nº of features for each example/user\n",
    "n_u = 100    # Nº de users\n",
    "n_rr = 0.25    # Percentage of valuations known in advance\n",
    "\n",
    "# Create an X with random values and size (m, n)\n",
    "# Insert a column of 1s in the first column\n",
    "X_true = [...]\n",
    "\n",
    "# Create a Theta_true with random values and size  (n + 1, n_u)\n",
    "Theta_true = [...]\n",
    "\n",
    "# Create a Y_true of size (m, n_u) by multiplying X_true and transposed Theta_true\n",
    "Y_true = [...]\n",
    "\n",
    "# Create an R matrix of 0s with size  (m, n_u)\n",
    "r = [...]\n",
    "count_r = round(n_rr * r.size)    # nº of known valuations or 1s in R\n",
    "while count_r:\n",
    "    # Generate a random int between [0, m] as an index of R\n",
    "    i = [...]\n",
    "    # Generate a random int between [0, n_u] as an index of R\n",
    "    j = [...]\n",
    "    \n",
    "    # Change that element from R to 1 if it has not been changed before and subtract 1 from the number of known ratings\n",
    "    if not r[i, j]:\n",
    "        r[i, j] = 1.\n",
    "\n",
    "        count_r -= 1\n",
    "\n",
    "# Count values of R other than 0.\n",
    "n_r = [...]\n",
    "\n",
    "# Generate a Y with only the known valuations using R\n",
    "y = [...]\n",
    "\n",
    "print('Size of X(m, n+1), Theta(n+1, n_u) and Y(m, n_u) true:')\n",
    "print(X_true.shape, Theta_true.shape, Y_true.shape)\n",
    "print('Size of y and R known in advance:')\n",
    "print(y.shape, r.shape)\n",
    "print('Nº of elements of R or known valuations:', n_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8ace8-340b-49fb-944c-3a84114842d6",
   "metadata": {},
   "source": [
    "# Cost and gradient descent functions\n",
    "\n",
    "We will implement the regularized cost function and gradient descent to train the ML model.\n",
    "\n",
    "Conceptually, we will follow different steps from linear regression:\n",
    "\n",
    "Whereas in linear regression *Y* and *X* were known, and we could iteratively optimize $\\Theta$ to reduce the cost, here *X* is not known in advance, as it is usually impossible in practice to know or have all the features of all the examples or films written down in advance.\n",
    "\n",
    "Also, while we do have some user ratings for some films, we typically have a fairly low percentage of ratings for each example, so *Y* is not completely known beforehand and most of its values will be initially empty.\n",
    "\n",
    "Therefore, our goal will be, not to solve $\\Theta$ but rather *Y* to fill it by obtaining all the predicted ratings of each user for each example.\n",
    "\n",
    "Therefore, the training algorithm will be:\n",
    "1. We collect the examples in matrices *X*, $\\Theta$ and *Y*.\n",
    "1. We mark the known valuations in the sparse *R* matrix.\n",
    "1. Given *X* and *Y*, we can obtain $\\Theta$.\n",
    "1. Given $\\Theta$ and *Y*, we can obtain *X*.\n",
    "1. We iteratively estimate X and $\\Theta$ at each iteration until the training converges to a minimum cost.\n",
    "1. When more valuations are available, we retrain the model by adding them to *Y* and marking them in *R*.\n",
    "\n",
    "In the next cell, follow the instructions to implement the regularized cost function and gradient descent for a collaborative filter, following the formulas below::\n",
    "\n",
    "$$ \\min\\limits_{\\theta^0, ..., \\theta^{n_u}, x^0, ..., x^{n_m}} J(x^0, ..., x^{n_m}, \\theta^0, ..., \\theta^{n_u}) = \\min\\limits_{\\theta^0, ..., \\theta^{n_u}, x^0, ..., x^{n_m}} [\\frac{1}{2} \\sum\\limits_{(i, k): r(i, k)=1} (x^i \\times \\theta^T_k - y^i_k)^2 $$\n",
    "$$ + \\frac{\\lambda}{2} \\sum\\limits_{i=0}^{n} \\sum\\limits_{k=0}^{n_u} (x^i_k)^2 + \\frac{\\lambda}{2} \\sum\\limits_{j=0}^{n} \\sum\\limits_{k=0}^{n_u} (\\theta^j_k)^2] $$\n",
    "$$ x^i_k := x^i_k - \\alpha (\\sum\\limits_{j: r(i, k) = 1} (x^i \\times \\theta^T_k - y^i_k) \\theta^j_k + \\lambda x^i_k); $$\n",
    "$$ \\theta^j_k := \\theta^j_k - \\alpha (\\sum\\limits_{i: r(i, k) = 1} (x^i \\times \\theta^{j T}  - y^i_k) x^i_k + \\lambda \\theta^j_k); \\space j = 0 \\rightarrow \\lambda = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590224a-ba26-4fe0-92de-e7ee9eed70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the cost function for collaborative filters\n",
    "\n",
    "def cost_function_collaborative_filtering_regularized(x, theta, y, r, lambda_=0.):\n",
    "    # TIPS: Plot the operations step by step on paper, noting the dimensions of the original vectors and those of the result of each intermediate operation\n",
    "    # Use ndarray.reshape() if you need to, especially with 1D vectors (e.g. (6,)) that can give you unexpected results in Numpy\n",
    "    # Use m, n, and n_u in ndarray.reshape(), not \"hard-coded\" values like 6, 20, etc.\n",
    "    # Use np.matmul() to multiply matrices\n",
    "    # To train on only known values, multiply R by the result of the subtraction of the hypothesis e and the mask matrix\n",
    "    # In choosing the slices or vectors of X, Theta and Y correctly, there is no major difference with linear regression\n",
    "    j = [...]\n",
    "\n",
    "    # Calculate the regularisation factor for X\n",
    "    x_reg = [...]\n",
    "\n",
    "    # Calculate the regularisation factor for Theta\n",
    "    # Remember not to regularise the first column\n",
    "    theta_reg = [...]\n",
    "\n",
    "    j = [...]\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d109198-0563-4e50-bcae-07e61a209323",
   "metadata": {},
   "source": [
    "### Check the implementation of the cost function\n",
    "\n",
    "Check your implementation of the cost function in the following scenarios:\n",
    "1. If `theta = Theta_true`, `j = 0`\n",
    "1. If `theta = Theta_true` y `lambda_ != 0`, `j != 0`\n",
    "1. The further `lambda_` moves away from 0 or `theta`, the more `j` increases\n",
    "1. 4.	If all the elements of `r` are 0, then no elements are considered for training, therefore `j = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955b1ff-3126-45e6-b4a7-718c1973df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the implementation of the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7e5d5-9ae8-462b-b74c-8323b8100408",
   "metadata": {},
   "source": [
    "Record your results in this cell:\n",
    "1. Experiment 1\n",
    "1. Experiment 2\n",
    "1. Experiment 3\n",
    "1. Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20dc04-776b-4597-a1d0-c008b4fd4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement gradient descent training for collaborative filters\n",
    "\n",
    "def gradient_descent_collaborative_filtering_regularized(x, theta, y, r, lambda_=0., alpha=1e-3, n_iter=1e3, e=1e-3):\n",
    "    # To train on only known values, multiply R by the result of the subtraction of the hypothesis e and the mask matrix\n",
    "\n",
    "    n_iter = int(n_iter)    # Convert n_iter to int so it can be used in range()\n",
    "    \n",
    "    # Initialise j_hist with the vlaues from the history of the cost function\n",
    "    j_hist = []\n",
    "    # Add as first value the cost of the cost function for the initial values\n",
    "    j_hist.append(cost_function_collaborative_filtering_regularized([...]))\n",
    "    \n",
    "    for iter_ in range(n_iter):\n",
    "        # Initialise some empty theta and x to fill in the gradient with ndarrays of the same size as the original ones\n",
    "        # and empty vector values (more optimized), zeros or random, so as not to modify theta, which must be kept constant during the iteration iter_\n",
    "        theta_grad = [...]\n",
    "        x_grad = [...]\n",
    "                \n",
    "        for k in range(n_u):\n",
    "            # Calculate the gradient to update theta at this iteration\n",
    "            # Use theta and not theta_grad in the intermediate operations, since we want to modify theta_grad and not the original theta\n",
    "            theta_grad[:, k] = [...]\n",
    "            \n",
    "            # For all theta_grad, except the first column, add the regularization term\n",
    "            theta_grad[1:, k] += [...]\n",
    "            \n",
    "        for i in range(m):\n",
    "            # Calculate the gradient to update X at this iteration\n",
    "            # Follow similar steps to the theta gradient to implement the corresponding function\n",
    "            # Add the regularisation term\n",
    "            x_grad[i, :] = [...]\n",
    "\n",
    "        # Update X and Theta with the gradients\n",
    "        x -= alpha * x_grad\n",
    "        theta -= alpha * theta_grad\n",
    "        \n",
    "        # If you need to, check how X and Theta are being updated\n",
    "        #print('\\nUpdated values of X and Theta')\n",
    "        #print(x)\n",
    "        #print(x.shape)\n",
    "        #print(theta)\n",
    "        #print(theta.shape)\n",
    "        \n",
    "        # Calculate the cost at this iteration and add it to the cost history\n",
    "        j_cost = cost_function_collaborative_filtering_regularized([...])\n",
    "        j_hist.append(j_cost)\n",
    "\n",
    "        # If it is not the first iteration and the absolute difference between the cost and that of the previous iteration is\n",
    "        # less than e, declare convergence\n",
    "        if [...]:\n",
    "            print('Converge at iteration nº', iter_)\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        print('Max. number of iterations {} reached'.format(n_iter))\n",
    "        \n",
    "    return j_hist, x, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a8990-aa9b-4eea-8548-7ad438bf30fe",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "Once the corresponding functions have been implemented, we will train the model.\n",
    "\n",
    "To do this, complete the following code cell with steps equivalent to other models from previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f655c-ffe0-422e-a177-6f1d5a122a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a collaborative filter recommendation system model\n",
    "\n",
    "# Generate an initial X and Theta with random values and the same size as X_true and Theta_true\n",
    "x_init = [...]\n",
    "theta_init = [...]\n",
    "\n",
    "alpha = 1e-2\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "n_iter = 1e4\n",
    "print('Hyperparameters used:')\n",
    "print('Alpha:', alpha, 'Lambda:', lambda_, 'Error:', e, 'Nº iter', n_iter)\n",
    "\n",
    "t0 = time.time()\n",
    "j_hist, x, theta = gradient_descent_collaborative_filtering_regularized([...])\n",
    "print('Training duration:', time.time() - t0)\n",
    "\n",
    "print('\\nLast 10 values of the cost function:')\n",
    "print(j_hist[-10:])\n",
    "print('\\nFinal error:')\n",
    "print(j_hist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64f791-45ea-4957-8c18-2009dc51d6a3",
   "metadata": {},
   "source": [
    "As we have done on previous occasions, plot the evolution of the cost function to check that the training of the model has been done correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e26ca-661d-4ea2-a24f-14b489f691d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the model training cost function vs. the number of iterations\n",
    "plt.figure()\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "# Add a title, label both axes of the graph, and a grid\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892402c7-fcd9-46e0-8ff1-73a75c66513c",
   "metadata": {},
   "source": [
    "### Check the implementation of the gradient descent\n",
    "\n",
    "Check your model training implementation in the following scenarios:\n",
    "1. If `theta = Theta_verd`, the model converges in 1 or 2 iterations with a final cost `j = 0`\n",
    "1. The further `theta` moves away from `Theta_verd`, the higher the intermediate cost and the more iterations until the model converges\n",
    "1. The more elements `r` has, the less time it takes to converge and the lower the final cost of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebee2d-84dd-4202-b993-4159a10e1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the implementation of gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c4874-f19c-49bc-8661-7ac4b8587f94",
   "metadata": {},
   "source": [
    "Record your results in this cell:\n",
    "1. Experiment 1\n",
    "1. Experiment 2\n",
    "1. Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ae0f6-655e-4f63-bbe7-76b52a0ec1ee",
   "metadata": {},
   "source": [
    "# Making predictions of recommendations\n",
    "\n",
    "Once the model has been trained, we can solve the recommendation matrix *Y*, which contains both the ratings issued by the users and a prediction of each user's rating for each example.\n",
    "\n",
    "Remember that we used the *R* matrix to mark actual valuations with a 1, while those that have been predicted and were not known beforehand are marked with a 0.\n",
    "\n",
    "To make a prediction and recommend examples to users (e.g., films), follow the instructions to complete the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25360e3-30b9-495a-be2e-116a70d762fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions of examples for users\n",
    "\n",
    "# Display the ratings of the Y matrix\n",
    "print('Pre-known values (first 10 rows and columns):')\n",
    "print(y[:10, :10] * r[:10, :10])    # # Limit the number of rows and columns of Y to display it on screen\n",
    "# Show more or fewer rows and columns if necessary to validate your model\n",
    "# In the result, a value of \"0.\" indicates a \"0.\" at that position in R, or that this initial valuation is not known\n",
    "\n",
    "# Calculate the predictions obtained by the model from X and Theta\n",
    "y_pred = [...]\n",
    "\n",
    "print('\\nPredicted ratings (first 10 rows and columns):')\n",
    "print(y_pred[:10, :10])\n",
    "\n",
    "# Calculate the residuals for the predictions\n",
    "# Remember that the residuals are the difference in absolute value between the previously known true value and the model predictions\n",
    "# Remember to calculate them only when the initial valuation is known, multiplying the residuals by R\n",
    "y_residual = [...]\n",
    "\n",
    "print('\\nModel residuals (first 10 rows and columns):')\n",
    "print(y_residual[:10, :10])\n",
    "\n",
    "# Display the initial predictions and ratings of a given user\n",
    "jj = 0    # Choose a user index between 0 and n_u\n",
    "\n",
    "print('\\nActual and predicted ratings for user no. {}:'.format(jj + 1))\n",
    "print(y_pred[:, jj])\n",
    "\n",
    "# Sort the indexes of the examples we would recommend to each user according to their ratings, in descending order\n",
    "# Remember to remove the ratings initially issued by the user from the list, or films already viewed, those whose R[i, k] == 0\n",
    "# You can sort a ndarray with numpy.sort()\n",
    "print('\\nPredicted ratings for user no. {}:'.format(jj + 1))\n",
    "print([...])\n",
    "\n",
    "# Puedes obtener los índices que ordenarían un ndarray con numpy.argsort()\n",
    "y_pred_ord = [...]\n",
    "\n",
    "print('\\nÍndices de los ejemplos a recomendar para el usuario {}, en función de sus valoraciones predichas:'.format(jj + 1))\n",
    "print(y_pred_ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5d716-ee67-4e59-850d-39570a46d4f7",
   "metadata": {},
   "source": [
    "# Reentrenar incorporando nuevas valoraciones\n",
    "\n",
    "Para reentrenar el modelo incorporando nuevas valoraciones de los usuarios, sólo hay que modificar la *Y* inicial con las nuevas valoraciones y marcar con un 1. la posición en la matriz *R*.\n",
    "\n",
    "Sigue las instrucciones de la siguiente celda para incorporar nuevas valoraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b537583-1d0b-4207-9edb-1c5b07d57d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Incorpora 2 nuevas valoraciones de usuarios a 2 ejemplos a tu elección\n",
    "\n",
    "# Escoge un índice de usuario y de ejemplo\n",
    "i_1 = 2\n",
    "k_1 = 2\n",
    "i_2 = 3\n",
    "k_3 = 3\n",
    "\n",
    "# Escoge una valoración. Habitualmente toman valores entre [0, 2)\n",
    "y[...] = 1.    \n",
    "y[...] = 1.\n",
    "\n",
    "# Márcalas como nuevas valoraciones en R\n",
    "r[...] = 1.\n",
    "r[...] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0adfad5-311a-4e6e-a548-f25082bca856",
   "metadata": {},
   "source": [
    "Ahora reentrena el modelo reejecutando la celda de entrenamiento y las siguientes hasta la celda anterior.\n",
    "\n",
    "Comprueba cómo dichas posiciones muestran ahora la nueva valoración y no una predicción del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a3ad21-4b09-4561-92c1-e7277bddaefe",
   "metadata": {},
   "source": [
    "# Encontrar ejemplos y usuarios similares\n",
    "\n",
    "Para encontrar la similitud entre 2 elementos, podemos computar la distancia euclídea entre ambos.\n",
    "\n",
    "La distancia euclídea en este espacio n-dimensional representará la diferencia acumulada entre los coeficientes de dichos elementos, al igual que una distancia en un plano 2D o 3D es la diferencia acumulada entre las coordenadas de dichos puntos.\n",
    "\n",
    "Encuentra ejemplos y usuarios similares siguiendo las instrucciones de la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7dc3e-3c03-4d68-814a-35a7c76a7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encuentra ejemplos y usuarios similares entre sí\n",
    "\n",
    "# Calcula la similaridad entre los 4 primeros ejemplos (X)\n",
    "dist_ej = distance.cdist([...])\n",
    "\n",
    "print('Similariad entre los 4 primeros ejemplos:')\n",
    "print(dist_ej)\n",
    "\n",
    "# Calcula la similaridad entre los 4 primeros usuarios (Theta)\n",
    "dist_us = distance.cdist([...])\n",
    "\n",
    "print('Similariad entre los 4 primeros usuarios:')\n",
    "print(dist_us)\n",
    "\n",
    "# Calcula el ejemplo más similar al primero\n",
    "index_ej_similar = [...]\n",
    "ej_similar = [...]\n",
    "\n",
    "print('Coeficientes del ejemplo nº {} para los 5 primeros usuarios:'.format(0 + 1))\n",
    "print(x[0, :5])\n",
    "print('El ejemplo más similar al nº {} es el ejemplo nº {}'.format(0 + 1, index_ej_similar))\n",
    "print('Coeficientes del ejemplo nº {} para los 5 primeros usuarios:'.format(index_ej_similar))\n",
    "print(ej_similar[:5])\n",
    "\n",
    "# Calcula el usuario más similar al primero\n",
    "index_us_similar = [...]\n",
    "us_similar = [...]\n",
    "\n",
    "print('Coeficientes del usuario nº {} para los 5 primeros ejemplos:'.format(0 + 1))\n",
    "print(theta[0, :5])\n",
    "print('El usuario más similar al nº {} es el usuario nº {}'.format(0 + 1, index_us_similar))\n",
    "print('Coeficientes del usuario nº {} para los 5 primeros ejemplos:'.format(index_us_similar))\n",
    "print(us_similar[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fc92f-aeba-4458-877e-b38a296819ab",
   "metadata": {},
   "source": [
    "## Bonus: Comprobar qué sucede si no disponemos de suficientes valoraciones iniciales\n",
    "\n",
    "*¿Qué sucede si no tenemos un nº mínimo de valoraciones inicialmente? ¿Y si hay algún ejemplo que no cuenta con ninguna valoración de ningún usuario, o un usuario que no ha valorado ningún ejemplo?*\n",
    "\n",
    "*¿Crees que, en ese caso, podríamos entrenar el modelo y obtener resultados para dichos ejemplos y usuarios?*\n",
    "\n",
    "Para comprobarlo, puedes p. ej. disminuir el porcentaje de valoraciones iniciales hasta un valor demasiado bajo, p. ej. un 10%, y comprobar qué sucede con la evolución de la función de coste del entrenamiento."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
