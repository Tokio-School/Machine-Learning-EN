{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5ab6b9-f3bd-41e8-8c75-952424a55a6d",
   "metadata": {},
   "source": [
    "# Recommender systems: Collaborative filters\n",
    "M4U2 - Exercise 1\n",
    "\n",
    "## What are we going to do?\n",
    "- We will investigate the collaborative filtering approach\n",
    "- We will create a dataset to be solved by recommender systems\n",
    "- We will implement the cost and gradient descent functions\n",
    "- We will train a recommendation model using collaborative filters\n",
    "- We will make predictions of recommendations\n",
    "- We will retrain the model by incorporating new valuations\n",
    "- We will recommend similar examples to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230b199-0f17-4353-8da2-8d07822a97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use this cell to import all the necessary libraries\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e17d9-1823-40a8-86e1-1c28832c52f3",
   "metadata": {},
   "source": [
    "# Create a synthetic dataset\n",
    "\n",
    "A common example is film recommendations on a video streaming portal. In this case, a dataset would have these features e.g.:\n",
    "- *m*: Nº of films.\n",
    "- *n*: Number of features of each film and coefficients of each user for them.\n",
    "- $n_u$: Nº of portal users.\n",
    "- $n_ru$ and $n_r$: Percentage of ratings for each film and total number of ratings, known in advance.\n",
    "- *X*: 2D matrix of features for each film, size (no of films, no of features).\n",
    "- $\\Theta$: 2D matrix of coefficients of each user for each film, size (nº of features, nº of users).\n",
    "- *Y*: 2D Matrix of ratings of each user for each film, size (nº of films, nº of users).\n",
    "\n",
    "We are going to create a synthetic dataset as usual, but this time focused on recommender systems, with some differences compared to linear regression:\n",
    "- The predictor or independent features *X* (size (*m*, *n* + 1)), which represents the features of each example, **are not known in advance**.\n",
    "- The vector $\\Theta$ (*Theta*) is 2D (size (*n* + 1, $n_u$)), since it now represents the coefficients of the features for each user. Again, **it is not known in advance**.\n",
    "- The vector *Y* is 2D (size (*m*, $n_u$)), as it now represents each user's rating for each example.\n",
    "- The vector *Y* will contain both the \"real\" ratings given by each user for each film they have rated, and, at the end of the training, their predicted ratings for recommending one film or another.\n",
    "- *R* will be a \"mask\" matrix over *Y*, used to indicate which ratings of *Y* are real and issued by a user, and therefore only those used to train the model.\n",
    "\n",
    "Para tener a mano, os dejamos esta tabla rápida para consultar el tamaño de cada matriz:\n",
    "- $X (m, n + 1)$\n",
    "- $\\Theta (n + 1, n_u)$\n",
    "- $Y (m, n_u)$\n",
    "\n",
    "Para no complicar más la implementación, en este caso no preprocesaremos los datos.\n",
    "\n",
    "Sigue las instrucciones para generar un dataset con las características necesarias para poder resolverlo por un filtro colaborativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613876f6-32c8-4675-9761-d20efcd76258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crea un dataset con las características necesarias para un sistema de recomendación\n",
    "# Recuerda que puedes volver a esta celda y modificar las características del dataset en cualquier momento\n",
    "\n",
    "m = 1000    # Nº de ejemplos\n",
    "n = 4    # Nº de características de cada ejemplo/usuario\n",
    "n_u = 100    # Nº de usuarios\n",
    "n_rr = 0.25    # Porcentaje de valoraciones conocidas de antemano\n",
    "\n",
    "# Crea una X con valores aleatorios y tamaño (m, n)\n",
    "# Inserta una columna de 1. en la primera columna\n",
    "X_verd = [...]\n",
    "\n",
    "# Crea una Theta_verd con valores aleatorios y tamaño (n + 1, n_u)\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Crea una Y_verd de tamaño (m, n_u) multiplicando X_verd y Theta_verd transpuesta\n",
    "Y_verd = [...]\n",
    "\n",
    "# Crea una matriz R de 0s con tamaño (m, n_u)\n",
    "r = [...]\n",
    "count_r = round(n_rr * r.size)    # nº de valoraciones conocidas o 1s en R\n",
    "while count_r:\n",
    "    # Genera un int aleatorio entre [0, m] como índice de R\n",
    "    i = [...]\n",
    "    # Genera un int aleatorio entre [0, n_u] como índice de R\n",
    "    j = [...]\n",
    "    \n",
    "    # Cambia dicho elemento de R a 1. si no se ha cambiado antes y resta 1 al nº de valoraciones conocidas\n",
    "    if not r[i, j]:\n",
    "        r[i, j] = 1.\n",
    "\n",
    "        count_r -= 1\n",
    "\n",
    "# Cuenta los valores de R que no sean 0.\n",
    "n_r = [...]\n",
    "\n",
    "# Genera una Y con sólo las valoraciones conocidas usando R\n",
    "y = [...]\n",
    "\n",
    "print('Tamaño de X(m, n+1), Theta(n+1, n_u) e Y(m, n_u) verdaderos:')\n",
    "print(X_verd.shape, Theta_verd.shape, Y_verd.shape)\n",
    "print('Tamaño de y y R conocidas de antemano:')\n",
    "print(y.shape, r.shape)\n",
    "print('Nº de elementos de R o valoraciones conocidas:', n_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8ace8-340b-49fb-944c-3a84114842d6",
   "metadata": {},
   "source": [
    "# Función de coste y descenso de gradiente\n",
    "\n",
    "Vamos a implementar la función de coste y el descenso de gradiente regularizados entrenar el modelo de ML.\n",
    "\n",
    "Conceptualmente, vamos a seguir unos pasos diferentes a los de la regresión lineal:\n",
    "\n",
    "Mientras que en la regresión lineal eran conocidas *Y* y *X* y podíamos optimizar iterativamente $\\Theta$ para reducir el coste, en esta ocasión *X* tampoco es conocida de antemano, ya que habitualmente es imposible en la práctica conocer o tener anotadas de antemano todas las características de todos los ejemplos o películas.\n",
    "\n",
    "Además, mientras que sí tenemos algunas valoraciones por cada usuario de algunas películas, solemos tener un porcentaje bastante bajo de valoraciones para cada ejemplo, por lo que *Y* no es completamente conocida de antemano sino que la mayoría de sus valores estarán vacíos inicialmente.\n",
    "\n",
    "Nuestro objetivo pues no será resolver $\\Theta$ sino *Y* para rellenarla obteniendo todas las valoraciones predichas de cada usuario para cada ejemplo.\n",
    "\n",
    "Por tanto, el algoritmo de entrenamiento será:\n",
    "1. Recopilamos los ejemplos y las valoraciones en las matrices *X*, $\\Theta$ e *Y*.\n",
    "1. Marcamos las valoraciones conocidas en la matriz dispersa *R*.\n",
    "1. Dadas *X* e *Y*, podemos obtener $\\Theta$.\n",
    "1. Dadas $\\Theta$ e *Y*, podemos obtener *X*.\n",
    "1. Estimamos de forma iterativa *X* y $\\Theta$ en cada iteración hasta que el entrenamiento converja en un coste mínimo.\n",
    "1. Cuando dispongamos de más valoraciones, reentrenamos el modelo añadiéndolas a *Y* y marcándolas en *R*.\n",
    "\n",
    "En la siguiente celda, sigue las instrucciones para implementar la función de coste y gradient descent regularizados para un filtro colaborativo, siguiendo las siguientes fórmulas:\n",
    "\n",
    "$$ \\min\\limits_{\\theta^0, ..., \\theta^{n_u}, x^0, ..., x^{n_m}} J(x^0, ..., x^{n_m}, \\theta^0, ..., \\theta^{n_u}) = \\min\\limits_{\\theta^0, ..., \\theta^{n_u}, x^0, ..., x^{n_m}} [\\frac{1}{2} \\sum\\limits_{(i, k): r(i, k)=1} (x^i \\times \\theta^T_k - y^i_k)^2 $$\n",
    "$$ + \\frac{\\lambda}{2} \\sum\\limits_{i=0}^{n} \\sum\\limits_{k=0}^{n_u} (x^i_k)^2 + \\frac{\\lambda}{2} \\sum\\limits_{j=0}^{n} \\sum\\limits_{k=0}^{n_u} (\\theta^j_k)^2] $$\n",
    "$$ x^i_k := x^i_k - \\alpha (\\sum\\limits_{j: r(i, k) = 1} (x^i \\times \\theta^T_k - y^i_k) \\theta^j_k + \\lambda x^i_k); $$\n",
    "$$ \\theta^j_k := \\theta^j_k - \\alpha (\\sum\\limits_{i: r(i, k) = 1} (x^i \\times \\theta^{j T}  - y^i_k) x^i_k + \\lambda \\theta^j_k); \\space j = 0 \\rightarrow \\lambda = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590224a-ba26-4fe0-92de-e7ee9eed70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función de coste para filtros colaborativos\n",
    "\n",
    "def cost_function_collaborative_filtering_regularized(x, theta, y, r, lambda_=0.):\n",
    "    # CONSEJOS: Plantea las operaciones paso a paso en papel, apuntando las dimensiones de los vectores originales y las del resultado de cada operación intermedia\n",
    "    # Utiliza ndarray.reshape() si lo necesitas, especialmente con vectores 1D (p. ej. (6,)) que pueden darte resultados no esperados en Numpy\n",
    "    # Usa m, n, n_u en ndarray.reshape(), no valores \"hard-coded\" como 6, 20, etc.\n",
    "    # Utiliza np.matmul() para multiplicar matrices\n",
    "    # Para entrenar sólo sobre valores conocidos, multiplica R por el resultado de la resta de la hipótesis e y como matriz de máscara\n",
    "    # Escogiendo los slices o vectores de X, Theta e Y correctamente, no hay gran diferencia con la regresión lineal\n",
    "    j = [...]\n",
    "\n",
    "    # Calcula el factor de regularización para X\n",
    "    x_reg = [...]\n",
    "\n",
    "    # Calcula el factor de regularización para Theta\n",
    "    # Recuerda no regularizar la primera columna\n",
    "    theta_reg = [...]\n",
    "\n",
    "    j = [...]\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d109198-0563-4e50-bcae-07e61a209323",
   "metadata": {},
   "source": [
    "### Comprobación de la implementación de la función de coste\n",
    "\n",
    "Comprueba tu implementación de la función de coste en las siguientes circunstancias:\n",
    "1. Si `theta = Theta_verd`, `j = 0`\n",
    "1. Si `theta = Theta_verd` y `lambda_ != 0`, `j != 0`\n",
    "1. Cuanto más se aleja `lambda_` de 0, a igual `theta`, más aumenta `j`\n",
    "1. Si todos los elementos de `r` son 0, no se considera ningún elemento para el entrenamiento, por lo tanto `j = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955b1ff-3126-45e6-b4a7-718c1973df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba la implementación de la función de coste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7e5d5-9ae8-462b-b74c-8323b8100408",
   "metadata": {},
   "source": [
    "Anota tus resultados en esta celda:\n",
    "1. Experimento 1\n",
    "1. Experimento 2\n",
    "1. Experimento 3\n",
    "1. Experimento 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20dc04-776b-4597-a1d0-c008b4fd4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa el entrenamiento por descenso de gradiente para filtros colaborativos\n",
    "\n",
    "def gradient_descent_collaborative_filtering_regularized(x, theta, y, r, lambda_=0., alpha=1e-3, n_iter=1e3, e=1e-3):\n",
    "    # Para entrenar sólo sobre valores conocidos, multiplica R por el resultado de la resta de la hipótesis e y como matriz de máscara\n",
    "\n",
    "    n_iter = int(n_iter)    # Convierte n_iter a int para poder usarlo en range()\n",
    "    \n",
    "    # Inicializa j_hist con el historial de valores de la función de coste\n",
    "    j_hist = []\n",
    "    # Añade como primer valor el coste de la función de coste para los valores iniciales\n",
    "    j_hist.append(cost_function_collaborative_filtering_regularized([...]))\n",
    "    \n",
    "    for iter_ in range(n_iter):\n",
    "        # Inicializa unas theta y x vacías para rellenar con el gradiente con ndarrays del mismo tamaño de los originales\n",
    "        # y valores de vector vacío (más optimizado), zeros o aleatorios, y así no modificar theta, que debe mantenerse constante durante la iteración iter_\n",
    "        theta_grad = [...]\n",
    "        x_grad = [...]\n",
    "                \n",
    "        for k in range(n_u):\n",
    "            # Calcula el gradiente para actualizar theta en esta iteración\n",
    "            # Utiliza theta y no theta_grad en las operaciones intermedias, ya que queremos modificar theta_grad y no la theta original\n",
    "            theta_grad[:, k] = [...]\n",
    "            \n",
    "            # Para toda theta_grad, excepto la primera columna, añade el término de regularización\n",
    "            theta_grad[1:, k] += [...]\n",
    "            \n",
    "        for i in range(m):\n",
    "            # Calcula el gradiente para actualizar X en esta iteración\n",
    "            # Sigue pasos similares al gradiente de theta para implementar la función correspondiente\n",
    "            # Suma el término de regularización\n",
    "            x_grad[i, :] = [...]\n",
    "\n",
    "        # Actualiza X y Theta con los gradientes\n",
    "        x -= alpha * x_grad\n",
    "        theta -= alpha * theta_grad\n",
    "        \n",
    "        # Si lo necesitas, comprueba cómo se van actualizando X y Theta\n",
    "        #print('\\nValores de X y Theta actualizados:')\n",
    "        #print(x)\n",
    "        #print(x.shape)\n",
    "        #print(theta)\n",
    "        #print(theta.shape)\n",
    "        \n",
    "        # Calcula el coste en esta iteración y añádelo al historial de costes\n",
    "        j_cost = cost_function_collaborative_filtering_regularized([...])\n",
    "        j_hist.append(j_cost)\n",
    "\n",
    "        # Si no es la primera iteración y la diferencia absoluta entre el coste y el de la iteración anterior es\n",
    "        # menor que e, declara la convergencia\n",
    "        if [...]:\n",
    "            print('Converge en iteración nº', iter_)\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        print('Nº máx. de iteraciones {} alcanzado'.format(n_iter))\n",
    "        \n",
    "    return j_hist, x, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a8990-aa9b-4eea-8548-7ad438bf30fe",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo\n",
    "\n",
    "Una vez implementadas las funciones correspondientes, vamos a entrenar el modelo.\n",
    "\n",
    "Para ello, completa la siguiente celda de código con pasos equivalentes a otros modelos de ejercicios previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f655c-ffe0-422e-a177-6f1d5a122a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de sistema de recomendación por filtros colaborativos\n",
    "\n",
    "# Genera una X y Theta inicial con valores aleatorios y el mismo tamaño que X_verd y Theta_verd\n",
    "x_init = [...]\n",
    "theta_init = [...]\n",
    "\n",
    "alpha = 1e-2\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "n_iter = 1e4\n",
    "print('Hiperparámetros usados:')\n",
    "print('Alpha:', alpha, 'Lambda:', lambda_, 'Error:', e, 'Nº iter', n_iter)\n",
    "\n",
    "t0 = time.time()\n",
    "j_hist, x, theta = gradient_descent_collaborative_filtering_regularized([...])\n",
    "print('Duración del entrenamiento:', time.time() - t0)\n",
    "\n",
    "print('\\nÚltimos 10 valores de la función de coste:')\n",
    "print(j_hist[-10:])\n",
    "print('\\nError final:')\n",
    "print(j_hist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64f791-45ea-4957-8c18-2009dc51d6a3",
   "metadata": {},
   "source": [
    "Como hemos hecho en ocasiones previas, representa gráficamente la evolución de la función de coste para comprobar que el entrenamiento del modelo ha sido correcto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e26ca-661d-4ea2-a24f-14b489f691d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente la función de coste del entrenamiento del modelo vs el nº de iteraciones\n",
    "plt.figure()\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "# Añade un título, etiquetas a ambos ejes de la gráfica y una rejilla\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892402c7-fcd9-46e0-8ff1-73a75c66513c",
   "metadata": {},
   "source": [
    "### Comprobación de la implementación del descenso de gradiente\n",
    "\n",
    "Comprueba tu implementación del entrenamiento del modelo en las siguientes circunstancias:\n",
    "1. Si `theta = Theta_verd`, el model converge en 1 o 2 iteraciones con un coste final `j = 0`\n",
    "1. Cuanto más se aleja `theta` de `Theta_verd`, hay un mayor coste intermedio y más iteraciones hasta que converge el modelo\n",
    "1. Cuantos más elementos tiene `r`, menos tarda en converger y menos coste final tiene el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebee2d-84dd-4202-b993-4159a10e1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba la implementación del descenso de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c4874-f19c-49bc-8661-7ac4b8587f94",
   "metadata": {},
   "source": [
    "Anota tus resultados en esta celda:\n",
    "1. Experimento 1\n",
    "1. Experimento 2\n",
    "1. Experimento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ae0f6-655e-4f63-bbe7-76b52a0ec1ee",
   "metadata": {},
   "source": [
    "# Realización de predicciones de recomendaciones\n",
    "\n",
    "Una vez entrenado el modelo, podemos resolver la matriz de recomendaciones *Y*, que contiene como decíamos tanto las valoraciones emitidas por los usuarios como una predicción de la valoración de cada usuario para cada ejemplo.\n",
    "\n",
    "Recuerda que utilizábamos la matriz *R* para marcar con un 1. las valoraciones reales y con un 0. aquellas que se han predicho y no eran conocidas de antemano.\n",
    "\n",
    "Para realizar una predicción y recomendar ejemplos a los usuarios (p. ej. películas), sigue las instrucciones para completar la siguiente celda de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25360e3-30b9-495a-be2e-116a70d762fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realiza predicciones de ejemplos para los usuarios\n",
    "\n",
    "# Muestra las valoraciones de la matriz Y\n",
    "print('Valoraciones conocidas de antemano (10 primeras filas y columnas):')\n",
    "print(y[:10, :10] * r[:10, :10])    # Limita el nº de filas y columnas de Y para mostrarlo por pantalla\n",
    "# Muestra más o menos filas y columnas si es necesario para validar tu modelo\n",
    "# En el resultado, un valor de \"0.\" indica un \"0.\" en esa posición en R, o que esa valoración inicial no es conocida\n",
    "\n",
    "# Calcula las predicciones obtenidas por el modelo a partir de X y Theta\n",
    "y_pred = [...]\n",
    "\n",
    "print('\\nValoraciones predichas (10 primeras filas y columnas):')\n",
    "print(y_pred[:10, :10])\n",
    "\n",
    "# Calcula los residuos de las predicciones\n",
    "# Recuerda que los residuos son la diferencia en valor absolutos entre el valor real previamente conocido y las predicciones del modelo\n",
    "# Recuerda calcularlos sólo cuando la valoración inicial es conocida, multiplicando los residuos por R\n",
    "y_residuo = [...]\n",
    "\n",
    "print('\\nResiduos del modelo (10 primeras filas y columnas):')\n",
    "print(y_residuo[:10, :10])\n",
    "\n",
    "# Muestra las predicciones y valoraciones iniciales de un usuario dado\n",
    "jj = 0    # Escoge un índice de usuario entre 0 y n_u\n",
    "\n",
    "print('\\nValoraciones reales y predichas para el usuario nº {}:'.format(jj + 1))\n",
    "print(y_pred[:, jj])\n",
    "\n",
    "# Ordena los índices de los ejemplos que recomendaríamos a cada usuario en función de sus valoraciones, en orden descendente\n",
    "# Recuerda eliminar de la lista las valoraciones emitidas inicialmente por el usuario, o películas ya vistas, aquellas cuya R[i, k] == 0\n",
    "# Puedes ordenar un ndarray con numpy.sort()\n",
    "print('\\nValoraciones predichas para el usuario nº {}:'.format(jj + 1))\n",
    "print([...])\n",
    "\n",
    "# Puedes obtener los índices que ordenarían un ndarray con numpy.argsort()\n",
    "y_pred_ord = [...]\n",
    "\n",
    "print('\\nÍndices de los ejemplos a recomendar para el usuario {}, en función de sus valoraciones predichas:'.format(jj + 1))\n",
    "print(y_pred_ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5d716-ee67-4e59-850d-39570a46d4f7",
   "metadata": {},
   "source": [
    "# Reentrenar incorporando nuevas valoraciones\n",
    "\n",
    "Para reentrenar el modelo incorporando nuevas valoraciones de los usuarios, sólo hay que modificar la *Y* inicial con las nuevas valoraciones y marcar con un 1. la posición en la matriz *R*.\n",
    "\n",
    "Sigue las instrucciones de la siguiente celda para incorporar nuevas valoraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b537583-1d0b-4207-9edb-1c5b07d57d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Incorpora 2 nuevas valoraciones de usuarios a 2 ejemplos a tu elección\n",
    "\n",
    "# Escoge un índice de usuario y de ejemplo\n",
    "i_1 = 2\n",
    "k_1 = 2\n",
    "i_2 = 3\n",
    "k_3 = 3\n",
    "\n",
    "# Escoge una valoración. Habitualmente toman valores entre [0, 2)\n",
    "y[...] = 1.    \n",
    "y[...] = 1.\n",
    "\n",
    "# Márcalas como nuevas valoraciones en R\n",
    "r[...] = 1.\n",
    "r[...] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0adfad5-311a-4e6e-a548-f25082bca856",
   "metadata": {},
   "source": [
    "Ahora reentrena el modelo reejecutando la celda de entrenamiento y las siguientes hasta la celda anterior.\n",
    "\n",
    "Comprueba cómo dichas posiciones muestran ahora la nueva valoración y no una predicción del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a3ad21-4b09-4561-92c1-e7277bddaefe",
   "metadata": {},
   "source": [
    "# Encontrar ejemplos y usuarios similares\n",
    "\n",
    "Para encontrar la similitud entre 2 elementos, podemos computar la distancia euclídea entre ambos.\n",
    "\n",
    "La distancia euclídea en este espacio n-dimensional representará la diferencia acumulada entre los coeficientes de dichos elementos, al igual que una distancia en un plano 2D o 3D es la diferencia acumulada entre las coordenadas de dichos puntos.\n",
    "\n",
    "Encuentra ejemplos y usuarios similares siguiendo las instrucciones de la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7dc3e-3c03-4d68-814a-35a7c76a7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encuentra ejemplos y usuarios similares entre sí\n",
    "\n",
    "# Calcula la similaridad entre los 4 primeros ejemplos (X)\n",
    "dist_ej = distance.cdist([...])\n",
    "\n",
    "print('Similariad entre los 4 primeros ejemplos:')\n",
    "print(dist_ej)\n",
    "\n",
    "# Calcula la similaridad entre los 4 primeros usuarios (Theta)\n",
    "dist_us = distance.cdist([...])\n",
    "\n",
    "print('Similariad entre los 4 primeros usuarios:')\n",
    "print(dist_us)\n",
    "\n",
    "# Calcula el ejemplo más similar al primero\n",
    "index_ej_similar = [...]\n",
    "ej_similar = [...]\n",
    "\n",
    "print('Coeficientes del ejemplo nº {} para los 5 primeros usuarios:'.format(0 + 1))\n",
    "print(x[0, :5])\n",
    "print('El ejemplo más similar al nº {} es el ejemplo nº {}'.format(0 + 1, index_ej_similar))\n",
    "print('Coeficientes del ejemplo nº {} para los 5 primeros usuarios:'.format(index_ej_similar))\n",
    "print(ej_similar[:5])\n",
    "\n",
    "# Calcula el usuario más similar al primero\n",
    "index_us_similar = [...]\n",
    "us_similar = [...]\n",
    "\n",
    "print('Coeficientes del usuario nº {} para los 5 primeros ejemplos:'.format(0 + 1))\n",
    "print(theta[0, :5])\n",
    "print('El usuario más similar al nº {} es el usuario nº {}'.format(0 + 1, index_us_similar))\n",
    "print('Coeficientes del usuario nº {} para los 5 primeros ejemplos:'.format(index_us_similar))\n",
    "print(us_similar[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fc92f-aeba-4458-877e-b38a296819ab",
   "metadata": {},
   "source": [
    "## Bonus: Comprobar qué sucede si no disponemos de suficientes valoraciones iniciales\n",
    "\n",
    "*¿Qué sucede si no tenemos un nº mínimo de valoraciones inicialmente? ¿Y si hay algún ejemplo que no cuenta con ninguna valoración de ningún usuario, o un usuario que no ha valorado ningún ejemplo?*\n",
    "\n",
    "*¿Crees que, en ese caso, podríamos entrenar el modelo y obtener resultados para dichos ejemplos y usuarios?*\n",
    "\n",
    "Para comprobarlo, puedes p. ej. disminuir el porcentaje de valoraciones iniciales hasta un valor demasiado bajo, p. ej. un 10%, y comprobar qué sucede con la evolución de la función de coste del entrenamiento."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
