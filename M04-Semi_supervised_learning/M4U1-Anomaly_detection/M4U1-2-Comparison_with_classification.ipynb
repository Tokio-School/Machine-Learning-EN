{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd38404-070a-43e8-9555-103e08cb11ed",
   "metadata": {},
   "source": [
    "# Detection of Anomalies: Comparison with classification\n",
    "M4U1 - Exercise 2\n",
    "\n",
    "## What are we going to do?\n",
    "- We will create a dataset for anomaly detection with normal and anomalous cases\n",
    "- We will train 2 models in a semi-supervised way, using SVM classification\n",
    "- We will evaluate both models and graphically represent their results\n",
    "\n",
    "Remember to follow the instructions for the submission of assignments indicated in [Submission Instructions](https://github.com/Tokio-School/Machine-Learning-EN/blob/main/Submission_instructions.md).\n",
    "\n",
    "## Instructions\n",
    "Anomaly detection methods that use Gaussian distribution covariance and the low probability of an event (used in the previous exercise) and those that use classification are similar, especially if we classify with a Gaussian kernel SVM, since both try to model a Gaussian distribution on the data.\n",
    "\n",
    "Their main differences are only noticeable in some circumstances, e.g.:\n",
    "- If the distribution of the normal examples is not Gaussian/normal or has multiple centroids that we have not detected beforehand.\n",
    "- In a high-dimensional dataset, where determining the normal distribution of the data is more difficult.\n",
    "- Classification, being a supervised learning method, requires a higher percentage of outliers than reinforcement learning.\n",
    "\n",
    "In this exercise we will combine both methods, which you have already solved in previous exercises, to analyse their results and differences.\n",
    "\n",
    "Follow the instructions below to solve the same dataset using both anomaly detection with Gaussian distribution, and SVM with a Gaussian kernel, copying code cells from previous exercises where possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c6d95-9326-41fd-837b-e561142d20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use this cell to import all the necessary libraries\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ad07b-5c1c-4927-9b92-ca2ad1a89100",
   "metadata": {},
   "source": [
    "## The steps we are going to take are\n",
    "\n",
    "We are going to create a synthetic dataset following the same steps as in the previous anomaly detection exercise. However, we will then create 2 different datasets, one for anomaly detection and one for classification, each with its 3 subsets of training, validation, and test data, since for Gaussian distribution covariance detection we do not assign outliers to the training subset, but for SVM classification we need to do so.\n",
    "\n",
    "Los pasos que vamos a dar son:\n",
    "1. Create a dataset with normal data and a dataset with outliers.\n",
    "1. Preprocess, normalise, and randomly reorder the data.\n",
    "1. Create training, validation, and test subsets to solve for Gaussian distribution covariance, with no outliers in the training subset.\n",
    "1. Create training, validation, and test subsets to solve by SVM with Gaussian kernel, with anomalous data (outliers) distributed across all the subsets.\n",
    "1. Plot the data for the 2 sets of subsets.\n",
    "\n",
    "Fill in the following code cells, copying your code from previous exercises whenever possible. At the end you should have generated, normalised, split, and reordered the ndarrays *X_gdc_train, X_gdc_val, X_gdc_test, X_svm_train, X_svm_val, X_svm_test* and their respective *Y* counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a1ff3-3553-467b-9334-e93847fd0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate two independent synthetic datasets with normal and outlier data\n",
    "\n",
    "m = 1000\n",
    "n = 2\n",
    "outliers_ratio = 0.25    # Percentage of outliers vs. normal data, modifiable\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb55a05-3d4c-4b5e-9f94-e87565edf03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalise the data of both datasets using the same normalisation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f52e9-e387-47ec-a267-6f216dc3ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Randomly reorder the 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf16730-4afc-4fc4-bd57-c5db85107265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide the 1st dataset into training, validation, and test subsets for Gaussian distribution covariance, with outliers only in the validation and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce249e-37a8-4627-9dc3-d326951c54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide the 2nd dataset into training, validation, and test subsets for Gaussian kernel SVM classification, with outliers distributed across all the subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd2e62-daf3-4913-a851-ac8dba830ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the 3 subsets on a 2D graph for both cases, indicating the normal data and the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de1756-e7f1-4a8c-aeee-74e6cdddadfe",
   "metadata": {},
   "source": [
    "## Anomaly detection resolution using normal distribution covariance\n",
    "\n",
    "To solve the dataset using normal distribution covariance, follow the steps from the previous exercise, copying the code of the corresponding cells and using the appropriate subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb11a2-1c57-40d2-a531-48c7ff240724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Model the Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069e298-0b08-47c4-9191-f3f66f9d4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Determine the probability threshold for detecting outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37ab6e-bf56-44ae-9c02-d443dce525ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the final accuracy of the model using its F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581637dc-e187-4123-95e1-944d94bbffab",
   "metadata": {},
   "source": [
    "## Resolution using SVM Classification\n",
    "\n",
    "Similarly, follow the steps in the SVM exercises above to classify the data into normal and outliers using SVM, copying the code from the corresponding cells and using the appropriate subsets.\n",
    "\n",
    "Use an RBF kernel with the Scikit-learn [OneClassSVM method](https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html) and *outlier_ratio* as the *nu* parameter. To regularise the model, optimise *gamma* with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddafc71-5ab0-48f7-8474-ddf0b9376005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a OneClassSVM model and optimise gamma on the validation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37e6e2-8ccf-4164-b5ce-611ce60e8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the final accuracy of the model using its F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0158269-7f0d-4a3e-8174-0e07ebda69df",
   "metadata": {},
   "source": [
    "## Comparison of the results of the two methods\n",
    "\n",
    "Now compare both methods, showing their F1-score and plotting their results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82776449-2ab4-4449-8afa-f9dc29550dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the F1-score results of both models\n",
    "\n",
    "print('F1-score of the Gaussian distribution covariance:')\n",
    "print()\n",
    "print('F1-score of the classification by SVM:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56050573-161e-4a05-bb49-e4bdc1df9c15",
   "metadata": {},
   "source": [
    "Plot the results of both models on their test subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615975d1-b4ee-4625-b6d6-2bb55daa6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot errors and hits next to the distribution and the epsilon cutoff threshold contour line\n",
    "# for the Gaussian distribution covariance\n",
    "\n",
    "# Assign z = 1 for hits, and z = 0 for misses\n",
    "# Hits: Y_test == Y_test_pred\n",
    "z_cdg = [...]\n",
    "\n",
    "# Plot the 2D graph\n",
    "# Use different colours for hits and misses\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed1cd3-8475-4dff-a905-490b7981899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot errors and hits next to the distribution and the border between classes\n",
    "# for classification by SVM\n",
    "\n",
    "# Assign z = 1 for hits, and z = 0 for misses\n",
    "# Hits: Y_test == Y_test_pred\n",
    "z_svm = [...]\n",
    "\n",
    "# Plot the graph\n",
    "# Use different colours for hits and misses\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efe636-82b7-41b5-b2ff-d5f93887856a",
   "metadata": {},
   "source": [
    "*What conclusions can you draw? What are the differences between the two methods?*"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
