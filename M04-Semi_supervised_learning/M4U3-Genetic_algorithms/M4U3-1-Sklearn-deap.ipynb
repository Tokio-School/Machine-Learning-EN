{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f66284-8b3a-495d-8831-d48b9beb9b81",
   "metadata": {},
   "source": [
    "# Genetic algorithms: Sklearn-deap\n",
    "M4U3 - Exercise 1\n",
    "\n",
    "## What are we going to do?\n",
    "- We will optimize training hyperparameters to validate a model using genetic algorithms\n",
    "- We will use the DEAP library via SKlearn-deap\n",
    "\n",
    "## Instructions\n",
    "Genetic algorithms are very useful for a wide variety of cases, where we want to optimise our system or function in an evolutionary way.\n",
    "\n",
    "However, they are particularly difficult to use effectively, as they add a large number of parameters that are not always easy to map to real system parameters: phenotypes, genotypes, mutational probabilities, mating and survival, etc.\n",
    "\n",
    "Moreover, they are not always particularly efficient at finding the most optimal solution and may fall into local minima.\n",
    "\n",
    "In this exercise we are going to give a very simple example of using, instead of Scikit-learn, validation methods like [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "For this we will use the [SKlearn-deap](https://github.com/rsteca/sklearn-deap)library to train a SVM classification model using cross-validation (K-fold).\n",
    "\n",
    "Follow the instructions in the following cells, building on the code from past exercises where possible and in this [example](https://github.com/rsteca/sklearn-deap/blob/master/test.ipynb) using SKlearn-deap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc969aab-ea3d-44e3-8945-ead9d8fcffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use this cell to import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda9e04-1c39-47ea-8441-71d3350912f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a synthetic dataset for classification with a significant error parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4debef9-281d-4e6c-96cd-1ec85dcf6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Preprocess the data: normalise it, split it into 2 training and test subsets and randomly reorder it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3083f-8a82-428f-856f-6f8f0ff4d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train an SVM model with cross-validation using genetic algorithms to select the best combination of\n",
    "# kernel and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c79ab2-c14b-4962-9218-a0dac2c5a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the F1-score of the model on the test subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3cd97-2665-477b-aa90-a015cac5bb64",
   "metadata": {},
   "source": [
    "*BONUS*: As you can see on the front page of the SKlearn-deap repository, it can also be used to maximise or minimise custom functions.\n",
    "\n",
    "*Could you use SKlearn-deap to minimize your manual implementation of the cost function for logistic regression?*\n",
    "\n",
    "*NOTE*: Try to use an error-free dataset with a low number of *n*-dimensions and no regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd0171-9738-4d34-a43b-36da78a357f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS TODO: Create a synthetic dataset for classification without an error parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04f597-27bc-48e3-99ba-7a488f7e690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS TODO: Copy your cost function for regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e174b-2dfa-4cb6-9aed-feb4bfa7e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS TODO: Optimize Theta by minimising your cost function using SKlearn-deap"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
